{
    "0": {
        "title": "Compositional Plan Vectors",
        "authors": "Coline Devin, Daniel Geng, Pieter Abbeel, Trevor Darrell, Sergey Levine",
        "abstract": "Autonomous agents situated in real-world environments must be able to master large repertoires of skills.\nWhile a single short skill can be learned quickly, it would be impractical to learn every task independently. Instead, the agent should share knowledge across behaviors such that each task can be learned efficiently, and such that the resulting model can generalize to new tasks, especially ones that are compositions or subsets of tasks seen previously.\nA policy conditioned on a goal or demonstration has the potential to share knowledge between tasks if it sees enough diversity of inputs. However, these methods may not generalize to a more complex task at test time. We introduce compositional plan vectors (CPVs) to enable a policy to perform compositions of tasks without additional supervision. CPVs represent trajectories as the sum of the subtasks within them. We show that CPVs can be learned within a one-shot imitation learning framework without any additional supervision or information about task hierarchy, and enable a demonstration-conditioned policy to generalize to tasks that sequence twice as many skills as the tasks seen during training.\n Analogously to embeddings such as word2vec in NLP, CPVs can also support simple arithmetic operations -- for example, we can add the CPVs for two different tasks to command an agent to compose both tasks, without any additional training.\n",
        "url_web": "https://papers.nips.cc/paper_files/paper/2019/hash/00989c20ff1386dc386d8124ebcba1a5-Abstract.html",
        "url_pdf": "https://papers.nips.cc/paper_files/paper/2019/file/00989c20ff1386dc386d8124ebcba1a5-Paper.pdf"
    },
    "1": {
        "title": "Learning to Propagate for Graph Meta-Learning",
        "authors": "LU LIU, Tianyi Zhou, Guodong Long, Jing Jiang, Chengqi Zhang",
        "abstract": "Meta-learning extracts the common knowledge from learning different tasks and uses it for unseen tasks. It can signi\ufb01cantly improve tasks that suffer from insuf\ufb01cient training data, e.g., few-shot learning. In most meta-learning methods, tasks are implicitly related by sharing parameters or optimizer. In this paper, we show that a meta-learner that explicitly relates tasks on a graph describing the relations of their output dimensions (e.g., classes) can signi\ufb01cantly improve few-shot learning. The graph\u2019s structure is usually free or cheap to obtain but has rarely been explored in previous works. We develop a novel meta-learner of this type for prototype based classi\ufb01cation, in which a prototype is generated for each class, such that the nearest neighbor search among the prototypes produces an accurate classi\ufb01cation. The meta-learner, called \u201cGated Propagation Network (GPN)\u201d, learns to propagate messages between prototypes of different classes on the graph, so that learning the prototype of each class bene\ufb01ts from the data of other related classes. In GPN, an attention mechanism aggregates messages from neighboring classes of each class, with a gate choosing between the aggregated message and the message from the class itself. We train GPN on a sequence of tasks from many-shot to few-shot generated by subgraph sampling. During training, it is able to reuse and update previously achieved prototypes from the memory in a life-long learning cycle. In experiments, under different training-test discrepancy and test task generation settings, GPN outperforms recent meta-learning methods on two benchmark datasets. Code of GPN is publicly available at: https://github.com/liulu112601/Gated-Propagation-Net.\n",
        "url_web": "https://papers.nips.cc/paper_files/paper/2019/hash/00ac8ed3b4327bdd4ebbebcb2ba10a00-Abstract.html",
        "url_pdf": "https://papers.nips.cc/paper_files/paper/2019/file/00ac8ed3b4327bdd4ebbebcb2ba10a00-Paper.pdf"
    }
}