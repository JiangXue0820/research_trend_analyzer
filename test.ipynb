{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0defcf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xue Jiang\\AppData\\Local\\Temp\\ipykernel_29076\\3422960472.py:15: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "import sys\n",
    "# sys.path.append(\"../\")\n",
    "from configs import config\n",
    "from configs.llm_provider import get_llm\n",
    "from tools.paper_fetch_tools_sql import paper_fetch_toolkit\n",
    "from tools.paper_analyze_tools import paper_analyze_toolkit\n",
    "from langchain_experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "\n",
    "# 1. Initialize LLM\n",
    "config.LLM_PROVIDER = 'gemini'\n",
    "llm = get_llm(config)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# 1. Create the planner (LLM decides on multi-step plan)\n",
    "planner = load_chat_planner(llm)\n",
    "\n",
    "# 2. Create the executor (agent capable of tool execution)\n",
    "executor = load_agent_executor(\n",
    "    llm=llm,\n",
    "    tools=paper_fetch_toolkit+paper_analyze_toolkit,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 3. Combine into plan-and-execute agent\n",
    "master_agent = PlanAndExecute(\n",
    "    planner=planner,\n",
    "    executor=executor,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# # 2. Create fetch and analyze agents\n",
    "# paper_fetch_agent = initialize_agent(\n",
    "#     tools=paper_fetch_toolkit,\n",
    "#     llm=llm,\n",
    "#     agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# paper_analyze_agent = initialize_agent(\n",
    "#     tools=paper_analyze_toolkit,\n",
    "#     llm=llm,\n",
    "#     agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "#     verbose=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ade714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.logging import configure_logging\n",
    "configure_logging()  # Make sure logging is set up first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0eb3033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xue Jiang\\AppData\\Local\\Temp\\ipykernel_29076\\931161638.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  master_agent.run(\"filter privacy-related papers from NIPS 2023, write a summary for each of the paper\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new PlanAndExecute chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 250\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 14\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResourceExhausted\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmaster_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfilter privacy-related papers from NIPS 2023, write a summary for each of the paper\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    188\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:603\u001b[39m, in \u001b[36mChain.run\u001b[39m\u001b[34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[39m\n\u001b[32m    601\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) != \u001b[32m1\u001b[39m:\n\u001b[32m    602\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`run` supports only one positional argument.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[32m    604\u001b[39m         _output_key\n\u001b[32m    605\u001b[39m     ]\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    608\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[32m    609\u001b[39m         _output_key\n\u001b[32m    610\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    188\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:386\u001b[39m, in \u001b[36mChain.__call__\u001b[39m\u001b[34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[32m    355\u001b[39m \n\u001b[32m    356\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    377\u001b[39m \u001b[33;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[32m    378\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    379\u001b[39m config = {\n\u001b[32m    380\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks,\n\u001b[32m    381\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m: tags,\n\u001b[32m    382\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m    383\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m: run_name,\n\u001b[32m    384\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:167\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    166\u001b[39m     run_manager.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    168\u001b[39m run_manager.on_chain_end(outputs)\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:157\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    156\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    159\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    160\u001b[39m     )\n\u001b[32m    162\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    163\u001b[39m         inputs, outputs, return_only_outputs\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain_experimental\\plan_and_execute\\agent_executor.py:43\u001b[39m, in \u001b[36mPlanAndExecute._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(\n\u001b[32m     39\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     40\u001b[39m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m     41\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     42\u001b[39m ) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     plan = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mplanner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m run_manager:\n\u001b[32m     48\u001b[39m         run_manager.on_text(\u001b[38;5;28mstr\u001b[39m(plan), verbose=\u001b[38;5;28mself\u001b[39m.verbose)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain_experimental\\plan_and_execute\\planners\\base.py:37\u001b[39m, in \u001b[36mLLMPlanner.plan\u001b[39m\u001b[34m(self, inputs, callbacks, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplan\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: \u001b[38;5;28mdict\u001b[39m, callbacks: Callbacks = \u001b[38;5;28;01mNone\u001b[39;00m, **kwargs: Any) -> Plan:\n\u001b[32m     36\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Given input, decide what to do.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     llm_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_parser.parse(llm_response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    188\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:608\u001b[39m, in \u001b[36mChain.run\u001b[39m\u001b[34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[39m\n\u001b[32m    603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[32m0\u001b[39m], callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[32m    604\u001b[39m         _output_key\n\u001b[32m    605\u001b[39m     ]\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m--> \u001b[39m\u001b[32m608\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[32m    609\u001b[39m         _output_key\n\u001b[32m    610\u001b[39m     ]\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    613\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    614\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    615\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m but none were provided.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    616\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    188\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:386\u001b[39m, in \u001b[36mChain.__call__\u001b[39m\u001b[34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[32m    355\u001b[39m \n\u001b[32m    356\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    377\u001b[39m \u001b[33;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[32m    378\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    379\u001b[39m config = {\n\u001b[32m    380\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks,\n\u001b[32m    381\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m: tags,\n\u001b[32m    382\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m    383\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m: run_name,\n\u001b[32m    384\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:167\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    166\u001b[39m     run_manager.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    168\u001b[39m run_manager.on_chain_end(outputs)\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:157\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    156\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    159\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    160\u001b[39m     )\n\u001b[32m    162\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    163\u001b[39m         inputs, outputs, return_only_outputs\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py:127\u001b[39m, in \u001b[36mLLMChain._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(\n\u001b[32m    123\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    124\u001b[39m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m    125\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    126\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.create_outputs(response)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain\\chains\\llm.py:139\u001b[39m, in \u001b[36mLLMChain.generate\u001b[39m\u001b[34m(self, input_list, run_manager)\u001b[39m\n\u001b[32m    137\u001b[39m callbacks = run_manager.get_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm, BaseLanguageModel):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    146\u001b[39m     results = \u001b[38;5;28mself\u001b[39m.llm.bind(stop=stop, **\u001b[38;5;28mself\u001b[39m.llm_kwargs).batch(\n\u001b[32m    147\u001b[39m         cast(\u001b[38;5;28mlist\u001b[39m, prompts), {\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks}\n\u001b[32m    148\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:980\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    971\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    972\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    973\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    977\u001b[39m     **kwargs: Any,\n\u001b[32m    978\u001b[39m ) -> LLMResult:\n\u001b[32m    979\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:799\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    796\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    797\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    798\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m799\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    805\u001b[39m         )\n\u001b[32m    806\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    807\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1045\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1043\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1045\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1049\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1441\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1414\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1415\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1416\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1427\u001b[39m     **kwargs: Any,\n\u001b[32m   1428\u001b[39m ) -> ChatResult:\n\u001b[32m   1429\u001b[39m     request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   1430\u001b[39m         messages,\n\u001b[32m   1431\u001b[39m         stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1439\u001b[39m         **kwargs,\n\u001b[32m   1440\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1441\u001b[39m     response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1443\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1444\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1445\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1446\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1447\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:231\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    222\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    224\u001b[39m params = (\n\u001b[32m    225\u001b[39m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[32m    226\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (request := kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[32m    230\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1520.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.1520.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:222\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[32m    219\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    220\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:206\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_with_retry\u001b[39m(**kwargs: Any) -> Any:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:868\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    865\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    867\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    167\u001b[39m     time.sleep(next_sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\AI_Learning\\AI_agent\\.venv\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mResourceExhausted\u001b[39m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.5-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 250\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 14\n}\n]"
     ]
    }
   ],
   "source": [
    "master_agent.run(\"filter privacy-related papers from NIPS 2023, write a summary for each of the paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f19d970d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Step' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m steps=[\u001b[43mStep\u001b[49m(value=\u001b[33m'\u001b[39m\u001b[33mAccess the official NeurIPS 2023 proceedings or paper list.\u001b[39m\u001b[33m'\u001b[39m), Step(value=\u001b[33m'\u001b[39m\u001b[33mSearch the paper titles and abstracts using keywords such as \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mprivacy,\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdifferential privacy,\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfederated learning,\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\u001b[33manonymity,\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconfidentiality,\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m and \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mprivacy-preserving.\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m), Step(value=\u001b[33m'\u001b[39m\u001b[33mReview the search results to identify papers primarily focused on privacy.\u001b[39m\u001b[33m'\u001b[39m), Step(value=\u001b[33m'\u001b[39m\u001b[33mSelect 10 distinct and relevant privacy-related papers from the identified list.\u001b[39m\u001b[33m'\u001b[39m), Step(value=\u001b[33m'\u001b[39m\u001b[33mPresent the titles and, if possible, authors or links for the 10 selected papers.\u001b[39m\u001b[33m'\u001b[39m), Step(value=\u001b[33m'\u001b[39m\u001b[33mGiven the above steps taken, please respond to the users original question.\u001b[39m\u001b[33m'\u001b[39m)]\n",
      "\u001b[31mNameError\u001b[39m: name 'Step' is not defined"
     ]
    }
   ],
   "source": [
    "steps=[Step(value='Access the official NeurIPS 2023 proceedings or paper list.'), Step(value='Search the paper titles and abstracts using keywords such as \"privacy,\" \"differential privacy,\" \"federated learning,\" \"anonymity,\" \"confidentiality,\" and \"privacy-preserving.\"'), Step(value='Review the search results to identify papers primarily focused on privacy.'), Step(value='Select 10 distinct and relevant privacy-related papers from the identified list.'), Step(value='Present the titles and, if possible, authors or links for the 10 selected papers.'), Step(value='Given the above steps taken, please respond to the users original question.')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d72f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "from utils.paper_crawler import download_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3437948",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = download_pdf(\"https://www.dfki.de/fileadmin/user_upload/import/5224_paper12.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ace9731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pymupdf.open(resp['data']['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e38d0313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document('temp/paper.pdf')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb49be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for page in doc:\n",
    "    text += page.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2300b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43265"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "175c2685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.llm_provider import get_text_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba381930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e44df39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = get_text_splitter(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70f52326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "document = [Document(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb3640b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Advances in Deep Parsing of Scholarly Paper\\nContent\\nUlrich Sch¨afer and Bernd Kiefer\\nLanguage Technology Lab\\nGerman Research Center for Artiﬁcial Intelligence (DFKI)\\nCampus D3 1, D-66123 Saarbr¨ucken, Germany\\n{ulrich.schaefer,kiefer}@dfki.de\\nhttp://www.dfki.de/lt\\nAbstract. We report on advances in deep linguistic parsing of the full\\ntextual content of 8200 papers from the ACL Anthology, a collection of\\nelectronically available scientiﬁc papers in the ﬁelds of Computational\\nLinguistics and Language Technology.\\nWe describe how – by incorporating new techniques – we increase both\\nspeed and robustness of deep analysis, speciﬁcally on long sentences\\nwhere deep parsing often failed in former approaches. With the current\\nopen source HPSG (Head-driven phrase structure grammar) for English\\n(ERG), we obtain deep parses for more than 85% of the sentences in the\\n1.5 million sentences corpus, while the former approaches achieved only\\napprox. 65% coverage.\\nThe resulting sentence-wise semantic representations are used in the Sci-\\nentist’s Workbench, a platform demonstrating the use and beneﬁt of\\nnatural language processing (NLP) to support scientists or other knowl-\\nedge workers in fast and better access to digital document content. With\\nthe generated NLP annotations, we are able to implement important,\\nnovel applications such as robust semantic search, citation classiﬁcation,\\nand (in the future) question answering and deﬁnition exploration.\\n1\\nIntroduction\\nScientists in all disciplines are nowadays faced with a ﬂood of new publications\\nevery day. In addition, more and more publications from the past become dig-\\nitally available and thus even increase the amount of data. Therefore, ﬁnding\\nrelevant information and avoiding redundancy and duplication of work have be-\\ncome urgent issues to be addressed by the scientiﬁc community.\\nThe organization and preservation of scientiﬁc knowledge in scientiﬁc pub-\\nlications, vulgo text documents, thwarts these eﬀorts. From a viewpoint of a\\ncomputer scientist, scientiﬁc papers are just ‘unstructured information’.\\nAutomatically precomputed, normalized semantic representations of textual\\nutterances could help to structure the search space and ﬁnd equivalent or related\\npropositions even if they are expressed diﬀerently, e.g. in passive constructions,\\nusing synonyms etc. Domain-relevant semantic similarity can be computed auto-\\nmatically and exploited as additional knowledge source to support robust search.\\n⋆Pre-print. The original publication is available at http://www.springerlink.com.\\n2\\nUlrich Sch¨afer and Bernd Kiefer\\nTo again constrain the so expanded search space, users can ask the system\\nin simply structured subject-predicate-object queries and get all matching, pre-\\ncomputed predicate-argument structures along with the original sentence from\\nthe paper. On the other hand, by storing the structure along with the original\\ntext in a structured full-text search engine such as Apache Lucene, it can be\\nguaranteed that recall cannot fall behind the baseline of a fulltext search engine.\\nThe basis of our scientiﬁc paper corpus is a subset of the ACL Anthology1,\\na collection of conference and workshop papers in the ﬁeld of Computational\\nLinguistics and Language Technology. We concentrate on 8200 papers from the\\nyears 2002 through 2009 from which we extracted the textual content using\\nAbbyy PDF Transformer.\\nExcept for named entity recognition which is partly based on instances and\\nconcepts of a domain ontology, the processing pipeline we describe below is\\nindependent of the science domain.\\nTo make the deep parser robust, it is embedded in a hybrid NLP workﬂow\\nstarting with a tokenizer, a part-of-speech tagger, and a named entity recognizer.\\nThese components help to identify and classify open class words such as person\\nnames, events (e.g. conferences) or locations. The trigram-based tagger helps\\nto guess part-of-speech tags of words unknown to the deep lexicon. For both\\nunknown words and named entities, generic lexicon entries are generated in the\\ndeep parser running the open source broad-coverage grammar ERG [5].\\nIn contrast to shallow parsers, the ERG not only handles detailed syntac-\\ntic analyses of phrases, compounds, coordination, negation and other linguistic\\nphenomena that are important for extracting semantic relations, but also gen-\\nerates a formal semantic representation of the meaning of the input sentence in\\nthe MRS (Minimal Recursion Semantics; [6]) representation format. Ambiguities\\nresulting in multiple readings per input sentence are ranked using a statistical\\nparse ranking model.\\nIn an earlier experiment, we obtained full deep parses for 64.89% of 955,581\\nsentences and 35.11% of the sentences were parsed by a fall-back shallow parser.\\nOnly 0.24% of the sentences could not be parsed at all.\\nIn this chapter, we describe the ﬁne-grained mapping of punctuation and\\nother tokenization details by means of a chart mapping technique [1] ensuring\\nthat this information is now optimally used by the deep grammar for disambigua-\\ntion. We also report on progress that we achieved by applying a chart pruning\\ntechnique [7] that, as already proven on another corpus, helps to considerably\\nincrease parsing speed of the deep parser and the number of successfully parsed\\nsentences. With both techniques applied together, we could not only increase\\nparsing speed considerably, but also the coverage on the ACL Anthology corpus\\nto more than 85%.\\nThis chapter is structured as follows. In section 2, we present the improved\\nparsing approach and results. In Section 3, we describe the semantic search\\napplication based on the improved parsing results. Section 4 discusses related\\nwork, and we ﬁnally conclude and give an outlook to future work in Section 5.\\n1 http://www.aclweb.org/anthology\\nAdvances in Deep Parsing of Scholarly Paper Content\\n3\\n2\\nDeep Parsing of Scholarly Papers\\nThe general idea of the semantics-oriented access to scholarly paper content is\\nto apply NLP analysis to each sentence they contain and distill a structured\\nrepresentation that can be searched for in addition to fulltext. Diﬀerent levels of\\nanalysis such as part-of-speech (PoS) tagging, named entity recognition (NER),\\nchunking, shallow and deep parsing are suitable for diﬀerent tasks.\\nWhile citation sentence classiﬁcation in scholarly papers, a further applica-\\ntion described in [16], is currently based on shallow NLP tasks such as tokeniza-\\ntion, PoS tagging and patterns thereof only, the semantic search application is\\nbased on the full range of hybrid, robustness-oriented NLP. This includes shal-\\nlow preprocessing with statistical taggers up to full deep parsing with generation\\nof sentence semantics representations from which basically predicate-argument\\nstructure is derived. Thus, both applications share the preprocessing, and in the\\nfuture, also citation sentence classiﬁcation could make use of linguistic features\\nextracted by more advanced NLP.\\n2.1\\nThe Corpus\\nThe basis of our scientiﬁc paper corpus is a subset of the ACL Anthology [2],\\na collection of conference and workshop papers in the ﬁeld of Computational\\nLinguistics and Language Technology. We concentrate on 8200 papers from the\\nyears 2002 through 2009 available in a native PDF format, i.e. not optically\\nscanned at limited quality such as many older papers. Except for named entity\\nrecognition which is partly based an a domain ontology, the processing pipeline\\nwe describe below is independent of the science domain. However, we expect\\nimprovements in the future by modeling domain knowledge, e.g. through auto-\\nmatically extracted domain speciﬁc terms and ontology concepts.\\n2.2\\nPDF Extraction\\nThe preprocessing step starts extracting clean text from the digital PDF docu-\\nments. In a ﬁrst version, we used PDFBox2 to gain raw text content from the\\npapers. This works well for most (especially recent) papers. However, it is prob-\\nlematic in general because PDFBox relies on the logical, digital content of the\\npage (layout) description language PDF. Its internal structure is very much de-\\npendent on the tool that was used to generate the PDF, and there are many tools\\nand of varying quality. Thus, decoding text from it does not work 100% correctly,\\nand imposes severe problems up to complete garbage because of non-standard\\ncharacter encodings or no output on about 10% of the corpus.\\nTo overcome these problems and become independent of the PDF encoder\\nthat was used to generate the digital paper, we recently moved to OCR-based\\nPDF extraction with the commercial product Abbyy PDF Transformer3. It also\\n2 http://pdfbox.apache.org\\n3 http://www.abbyy.com\\n4\\nUlrich Sch¨afer and Bernd Kiefer\\nreliably resolves hyphenated words using its own language model as well as text\\n(order) in tables. Moreover, and in contrast to PDFBox, it also works on scanned\\ndocuments, provided that the scan quality is good enough. However, recognition\\nof non-Latin characters such as in mathematical formulae remains a problem.\\nIt can be ignored for the time being because the NLP tools used also do not\\nunderstand mathematics.\\nAfter text extraction, a sentence splitter segments into sentence units in order\\nto provide suitable input for subsequent NLP. For each sentence, we record a\\nunique document ID (in case of our corpus the ACL Anthology paper ID, e.g.\\nC02-1023 for a paper from the COLING-2002 proceedings), the page on which\\nit appeared, and the sentence number relative to the whole document. Amongst\\nothers, this information is important to highlight a search result or citation\\nsentence within the original PDF paper layout.\\n2.3\\nHybrid Parsing\\nTo make the deep parser robust, it is embedded in a hybrid NLP workﬂow\\nimplemented using the hybrid NLP platform Heart of Gold [15]. Heart of Gold\\nis an XML-based middleware architecture for the integration of multilingual\\nshallow and deep natural language processing components, developed under the\\numbrella of the DELPH-IN initiative4.\\nThe employed Heart of Gold conﬁguration instance starts with a tokenizer,\\nthe shallow part-of-speech tagger TnT [3] and the named entity recognizer\\nSProUT [8]. These components help to identify and classify open class words\\nsuch as person names, events (e.g. conferences) or locations.\\nThe (trigram-based) tagger helps to guess part-of-speech tags of words un-\\nknown to the deep lexicon. For both unknown words and named entities, generic\\nlexicon entries are generated in the deep parser. By means of the PET input\\nchart XML format FSC [1], the shallow preprocessing results are combined and\\npassed to the high-speed HPSG [12] parser PET [4] running the open source\\nbroad-coverage grammar ERG [5] (cf. Fig 2).\\n2.4\\nPrecise Preprocessing Integration with Chart Mapping\\nChart mapping [1] is a novel mechanism for the non-monotonic, rule-based ma-\\nnipulation of chart items that are described by feature structures. There are\\ncurrently two chart mapping phases in PET during parsing: (1) Token map-\\nping, where input items as delivered by external preprocessors are adapted to\\nthe expectations of the grammar. This requires that input items are described\\nby feature structures – the token feature structures. (2) Lexical ﬁltering, where\\nlexical items can be ﬁltered by hard constraints after lexical parsing has ﬁnished.\\nToken mapping requires tokens to be described by feature structures. Token\\nfeature structures can be arbitrarily complex. This allows users to pass informa-\\ntion of various preprocessing modules into the parser. To this end, a new format,\\nthe XML-based FSC input format, was developed.\\n4 http://www.delph-in.net/heartofgold/\\nAdvances in Deep Parsing of Scholarly Paper Content\\n5\\nFollowing is an excerpt from the FSC for the sentence “Resnik and Smith\\n(2003) extract bilingual sentences from the Web to create parallel corpora for\\nmachine translation.” (from anthology document N07-1043) generated by Heart\\nof Gold preprocessing from TnT and SProUT output.\\n<fsc version=\"1.0\">\\n<chart id=\"hog://session1284321397757/collection1/TnT\">\\n<lattice init=\"v0\" final=\"v20\">\\n<edge source=\"v0\" target=\"v1\">\\n<fs type=\"token\">\\n<f name=\"+FORM\"><str>Resnik</str></f>\\n<f name=\"+FROM\"><str>0</str></f>\\n<f name=\"+TO\"><str>6</str></f>\\n<f name=\"+TNT\">\\n<fs type=\"tnt\">\\n<f name=\"+TAGS\" org=\"list\"><str>NNP</str></f>\\n<f name=\"+PRBS\" org=\"list\"><str>1.000000</str></f>\\n</fs>\\n</f>\\n</fs>\\n</edge>\\n... <!-- more token edges from TnT -->\\n<edge source=\"v6\" target=\"v7\">\\n<fs type=\"token\">\\n<f name=\"+FORM\"><str>extract</str></f>\\n<f name=\"+FROM\"><str>24</str></f>\\n<f name=\"+TO\"><str>31</str></f>\\n<f name=\"+TNT\">\\n<fs type=\"tnt\">\\n<f name=\"+TAGS\" org=\"list\"><str>VB</str></f>\\n<f name=\"+PRBS\" org=\"list\"><str>1.000000</str></f>\\n</fs>\\n</f>\\n</fs>\\n</edge>\\n... <!-- more token edges from TnT -->\\n<!-- this edge comes from the Named Entity Recognizer -->\\n<edge source=\"v0\" target=\"v6\">\\n<fs type=\"token\">\\n<f name=\"+FORM\"><str>Resnik and Smith (2003)</str></f>\\n<f name=\"+FROM\"><str>0</str></f>\\n<f name=\"+TO\"><str>23</str></f>\\n<f name=\"+TNT\"><fs type=\"null_tnt\"/></f>\\n<f name=\"+CLASS\"><fs type=\"proper_ne\"/></f>\\n<f name=\"+TRAIT\"><fs type=\"generic_trait\"/></f>\\n</fs>\\n</edge>\\n</lattice>\\n</chart>\\n</fsc>\\n6\\nUlrich Sch¨afer and Bernd Kiefer\\nFigure 1 shows how tokenized and PoS-tagged input is combined with pos-\\nsibly concurrent information from a named entity recognizer, in the example\\nSProUT delivering hypothetical information on named entities (here a citation\\nstring) in a single named entity item spanning over multiple words.\\nConcerning punctuation, the deep grammar can e.g. make use of information\\non opening and closing quotation marks. This information is often not explicit\\nin the input text, e.g. when gained through OCR techniques, which make no\\ndistinction between ‘ and ’ or “ and ”. However, a tokenizer can often guess\\n(reconstruct) leftness and rightness correctly. This information, passed to the\\ndeep parser via FSC, helps it to disambiguate.\\nv0\\nv1\\nFORM Resnik\\nFROM\\n0\\nTO\\n6\\nTNT\\nNNP\\nv6\\nFORM Resnik and Smith (2003)\\nFROM\\n0\\nTO\\n23\\nCLASS\\nproper_ne\\nv2\\nFORM and\\nFROM\\n7\\nTO\\n10\\nTNT\\nCC\\nv3\\nFORM Smith\\nFROM\\n11\\nTO\\n16\\nTNT\\nNNP\\nv4\\nFORM\\n(\\nFROM 17\\nTO\\n18\\nTNT\\n(\\nv5\\nFORM 2003\\nFROM\\n18\\nTO\\n22\\nTNT\\nCD\\nFORM\\n)\\nFROM 22\\nTO\\n23\\nTNT\\n)\\nFig. 1. FSC input to PET with combined information from tokenizer, PoS tagger and\\nconcurrent SProUT citation string item for input fragment “Resnik and Smith (2003)\\nextract ...”\\nFurthermore, a new way of generic lexical instantiation has been introduced\\nwith token feature structures and chart mapping. In this new setup, the parser\\ntries to instantiate all generic lexical entries for each word. Upon lexical instan-\\ntiation, the token feature is uniﬁed into a designated path of the lexical entry.\\nOnly if this uniﬁcation succeeds, the lexical item is instantiated. In order to con-\\ntrol the instantiation of generic lexical entries, the token feature structures are\\nappropriately constrained in the generic lexical entry, for instance by requiring\\nthat a generic verbal entry is only applicable for token feature structures where\\nthe highest ranked part-of-speech tag is a verb.\\n2.5\\nIncreased Processing Speed and Coverage through Chart\\nPruning\\nThe use of statistical models for result selection is well established for parsing\\nwith PET and ERG. We use a discriminative maximum entropy model based on\\nWeScience data [9] to compute the best parse results. Recently, [7] described the\\nuse of a generative model to increase eﬃciency by shaping the search space of\\nthe parser towards the more likely constituents and pruning very unlikely ones.\\nThis method not only results in lower parse times, but also in slightly better\\ncoverage, since sentences which could not be parsed due to timeouts now ﬁt into\\nthe given time bounds.\\nThe generative model is in fact a probabilistic context-free grammar (PCFG)\\ncomputed from the same tree banks as the discriminative model. The parser in\\nPET is a straightforward bottom-up chart parser with agenda, which makes it\\nAdvances in Deep Parsing of Scholarly Paper Content\\n7\\ninput\\nsentence\\ninput\\nsentence\\ntokenizer\\ntokenizer\\nPoS tagger\\nPoS tagger\\nnamed entity\\nrecognizer\\nnamed entity\\nrecognizer\\nPET parser\\nPET parser\\nPET XML\\ninput chart\\nPET XML\\ninput chart\\nMRX\\nMRX\\nsemantic tuples\\ndatabase\\nsemantic tuples\\ndatabase\\nsemantic tuples extractor\\nsemantic tuples extractor\\nFig. 2. Heart of Gold workﬂow for hybrid parsing and semantic tuples extraction\\neasy to use a model that has only local dependencies, such as PCFG. What\\nis missing is a heuristics to prune unlikely items in a way that has a small\\ncomputation overhead and will retain most of the items that are needed for the\\nglobally best results.\\n[11] did a very thorough comparison of diﬀerent performance optimization\\nstrategies, and among those also a local pruning strategy which is similar to the\\none used by [7]. It restricts the number of items given both their length and start\\npoint in the chart. This is easy to implement and avoids the use of complicated\\nheuristics to compensate the bias that shorter items become over longer chart\\nitems because of decreasing probability, which leads, without compensation, to\\na breadth-ﬁrst strategy for the whole parse. The number of items per chart cell\\nis restricted to a ﬁxed number to hinder the parser from getting lost in local\\nprobability maxima.\\nThere is an important diﬀerence to the system of [11], namely that their\\nsystem works on a reduced context-free backbone of the grammar and then\\nreconstructs the full results, while PET uses the full HPSG grammar directly,\\n8\\nUlrich Sch¨afer and Bernd Kiefer\\nwith subsumption packing and partial unpacking to achieve a similar eﬀect as\\nthe packed chart of a context-free parser.\\nThe local chart pruning results in a measurable speed-up with a negligible\\ndecrease in parsing accuracy; in fact, an increase in f-measure has been observed\\nbecause complicated sentences that had originally failed due to resource restric-\\ntions could now be parsed.\\n 0\\n 10\\n 20\\n 30\\n 40\\n 50\\n 60\\n 70\\n 80\\n 0\\n 20\\n 40\\n 60\\n 80\\n 100\\nsentences x 1000\\nmean parse time (CPU s)\\nsentence length −→\\nFig. 3. Distribution of sentence length and mean parse times for mild pruning\\nProcessing Results. In total, we parsed 1,537,801 sentences, of which 57,832\\n(3.8%) could not be parsed because of lexicon errors which are mostly due to\\nOCR artifacts.\\nFigure 3 displays the average parse time of processing with moderate chart\\npruning, together with the mean quadratic error. In addition, it contains the\\ndistribution of input sentences over sentence length. Obviously, the vast majority\\nof sentences has a length up to 60 words maximum.\\nParse time was limited to 60 CPU seconds, and main memory consumption\\nto 4 GB, which was far more than ever needed by the processes. Overall, the\\nparse times only grow mildly due to the many optimization techniques in the\\noriginal system, and also the new chart pruning method. The sentence length\\ndistribution has been integrated into Figure 3 to show that the predominant part\\nof our real-world corpus can be processed using this information-rich method\\nwith very modest parse times.\\nThe large amount of short inputs is at ﬁrst surprising, moreover as most of\\nthese inputs can not be parsed, as can be seen in Figure 5. The explanation\\nAdvances in Deep Parsing of Scholarly Paper Content\\n9\\nis easy: most of these inputs are non-sentences such as headings, enumerations,\\nfootnotes and such. How we deal with this kind of input will be described in the\\nsection about fragmentary input.\\nAll measurements were carried out on an Intel XEON E5430 2.66GHz cluster\\ncomputer. Except for the parallelization, the used hardware equals a modern\\nstandard desktop PC, which again shows the feasibility of the used method.\\n 0\\n 10\\n 20\\n 30\\n 40\\n 50\\n 60\\n 0\\n 20\\n 40\\n 60\\n 80\\n 100\\nno pruning\\nmax400\\nmax100\\nsentence length −→\\nMean parse time (CPU sec) over sentence length\\nNo pruning\\nMax. 400 passive Max. 100 passive\\nAvg. Parse Time (CPU sec)\\n5.90\\n3.95\\n2.17\\nUnparsed Sentences\\n433104 (28.2%) 392758 (25.5%)\\n381019 (24.8%)\\nRecall\\n71.8%\\n74.5%\\n75.2%\\nBest Parse Lost\\n5.43%\\n19.7%\\nFig. 4. Comparison of results with diﬀerent chart pruning settings\\nFigure 4 shows the eﬀects of the chart pruning approach using moderate\\nas well as more aggressive pruning. The last row displays the amount of parsed\\nsentences which do not get the best results due to pruning. Note that the increase\\nin parsed sentences is only due to the reduced resource needs through pruning,\\nand that the lexical failures are not contained in the unparsed sentences ﬁgures.\\nFigure 5 shows the amount of unparsed sentences, split into two categories.\\nThe dots represent the sentences that could not be parsed due to time limitations,\\nthe solid lines those that were rejected by the grammar. Not surprisingly, the\\nfraction of sentences hitting the time bound increases noticeably for sentences\\n10\\nUlrich Sch¨afer and Bernd Kiefer\\nlonger that 60 words, but it should be noted that the percentage that can not\\nbe parsed because of grammatical reasons stays almost constant.\\n 0\\n 10\\n 20\\n 30\\n 40\\n 50\\n 60\\n 70\\n 80\\n 90\\n 100\\n 0\\n 20\\n 40\\n 60\\n 80\\n 100\\nno pruning\\nno pruning timeout\\ncp400\\ncp400 timeout\\ncp100\\ncp100 timeout\\nsentence length −→\\nFig. 5. Percentage of unparsed sentences over sentence length\\nFor sentences with less than 40 words, aggressive chart pruning loses parses\\n(around 0.8%) that the mild pruning still does successfully, because edges needed\\nfor a full parse are pruned from the chart. In toto, the aggressive pruning gets\\nmore readings because it greatly improves recall on the longer sentences, but\\nsome are lost in the important middle range, which is also why we use the\\nresults from the mild pruning for the extraction of the semantics. An advanced\\nsystem could adapt pruning to the input length, or try to come up with better\\nlocal models that minimize the loss of useful subconstituents.\\nWe also compared the (absolute) scores of the discriminative model for the\\ntwo variants. While the method without chart pruning always ﬁnds the best\\nparse, this is not true for the pruned chart. The result is displayed in the fourth\\nrow of the table in Figure 4. Since the scores of the maximum entropy model\\nare not probabilities, we can not give meaningful numbers on the loss of quality,\\nbut a rough comparison of the scores suggests that in most cases the penalty is\\nminor.\\nFragmentary Input. There are several alternatives to deal with input like\\nheadings and footnotes, one to identify and handle them in a preprocessing\\nstep, another to use a special root condition in the deep analysis component\\nthat is able to combine phrases with well-deﬁned properties for inputs where no\\nspanning result could be found.\\nAdvances in Deep Parsing of Scholarly Paper Content\\n11\\nWe employed the second method, which has the advantage that it handles a\\nlarger range of phenomena in a homogeneous way. Figure 6 shows the change in\\npercentage of unparsed and timed out inputs for the mild pruning method with\\nand without the root condition combining fragments.\\n 0\\n 10\\n 20\\n 30\\n 40\\n 50\\n 60\\n 70\\n 80\\n 90\\n 100\\n 0\\n 20\\n 40\\n 60\\n 80\\n 100\\nstrict\\nstrict timeout\\nstrict+fragments\\nstrict+fragments timeout\\nsentence length −→\\nFig. 6. Unparsed and timed out sentences with and without fragment combination\\nAs Figure 6 shows nicely, this changes the curve for unparsed sentences to-\\nwards more expected characteristics and removes the uncommonly high percent-\\nage of short sentences for which no parse can be found.\\nTogether with the parses for fragmented input, we get a recall (sentences\\nwith at least one parse) over the whole corpus of 85.9% (1,321,336 sentences),\\nwithout a signiﬁcant change for any of the other numbers.\\n2.6\\nParser Output\\nIn contrast to shallow parsers, the ERG not only handles detailed syntactic\\nanalyses of phrases, compounds, coordination, negation and other linguistic phe-\\nnomena that are important for extracting relations, but also generates a formal\\nsemantic representation of the meaning of the input sentence in the MRS repre-\\nsentation format (Minimal Recursion Semantics; [6]). It is comparable to a ﬁrst\\norder logic form. It consists of so-called elementary predications for each token\\nand larger constituents, connected via argument positions and variables/labels,\\nfrom which the predicate-argument structure can be derived (example in Fig-\\nure 7).\\n12\\nUlrich Sch¨afer and Bernd Kiefer\\n⟨h1,\\nh3:udef q(x5{PERS 3, NUM sg}, h4, h6),\\nh7: semantic a 1(e8{SF prop, TENSE untensed, MOOD indicative}, x5),\\nh7: similarity n to(x5, i9),\\nh10: measure v 1(e2{SF prop, TENSE pres, MOOD indicative, PROG -, PERF -}, p11, x5),\\nh10:parg d(e12{SF prop}, e2, x5),\\nh10: in p(e13{SF prop, TENSE untensed, MOOD indicative}, e2, x14{PERS 3, NUM pl, IND +}),\\nh15:udef q(x14, h16, h17),\\nh18: term n of(x14, x19{PERS 3, NUM pl}),\\nh20:udef q(x19, h21, h22),\\nh23:compound(e25{SF prop, TENSE untensed, MOOD indicative, PROG -, PERF -}, x19, x24),\\nh26:udef q(x24, h27, h28),\\nh29: similar a to(e30{SF prop, TENSE untensed, MOOD indicative}, x24),\\nh29:comp(e32{SF prop}, e30, u31),\\nh29: word n of(x24, i33),\\nh23: context n 1(x19)\\n{ h27 =q h29, h21 =q h23, h16 =q h18, h4 =q h7 } ⟩\\nFig. 7. Sample MRS for the sentence “Semantic similarity is measured in terms of\\nsimilar word contexts.”\\nAs in previous work [18] and because of the increased parsing recall, we again\\nopt for precision and only use results from the deep parser instead of extending\\nthe hybrid workﬂow (Figure 2) in such a way that a shallow parser with less\\ndetailed analyses is used as fall-back in case deep parsing fails (as done in an\\nintermediate system, [17]).\\n3\\nApplication: Semantic Search Based on Extracted\\nPredicate-Argument Structure\\nThe idea of the semantic search application is to use the sentence-wise semantic\\nrepresentations generated oﬄine by the deep parser. From its output, a normal-\\nized predicate-argument structure is extracted that is stored in a search index.\\nThe main motivation is at least partial abstraction from syntactic variants. Thus,\\nthe extraction process includes dividing sentences with coordination into inde-\\npendent structures, and using the semantic subject and object in both active\\nand passive sentence construction independently of the syntactic realization.\\nThe user interface for this application is simple. Instead of a single search text\\ninput ﬁeld, the user will see three: one for subject, one for predicate and another\\none for further objects. This is easy to understand also for non-linguists, and\\nﬁelds may be left emtpy to match anything. In the current version, the search\\ninterface supports the use of synsets of predicates only.\\n3.1\\nExtracting Predicate-Argument Structure from MRS\\nThe MRS representations resulting from hybrid parsing are relatively close to\\nlinguistic structures and contain more detailed information than a user would\\nAdvances in Deep Parsing of Scholarly Paper Content\\n13\\nlike to query and search for. Therefore, an additional extraction and abstraction\\nstep is necessary before storing the semantic structures in the search index.\\nThe format we devised for this purpose we call semantic tuples, a blend of\\ntriples and quintuples, as we store quintuples (subject, predicate, direct object,\\nother complements and adjunct), but to ease search term input for the user, only\\ndistinguish between a triple of subject, predicate and any other objects in the\\nquery structure.\\nThe algorithm to generate the semantic tuples ﬁrst performs an intermedi-\\nate transformation into isomorphic, serializable Java objects that can be made\\npersistent. On these objects, eﬃcient graph manipulation resulting in extracted\\nsemantic tuples can take place. Handling of coordination has been implemented\\nby generating multiple tuples. Passive constructions are elegantly handled by\\nthe grammar itself and lead to identical semantic tuples regardless of active or\\npassive formulation of the same proposition.\\nDue to semantic ambiguity, the deep parser may return more than one reading\\nper sentence. Currently up to three readings are considered (the most probable\\nones according to the treebank-trained parse ranking model), and semantic tu-\\nples are generated for each reading respectively. Multiple readings may collapse\\ninto the same semantic tuple structure, in which case only a single one is stored\\nin the database. Otherwise, a voting mechanism based on rank and number of\\nisomorphic semantic tuples decides for the best selection.\\nThe following sentence includes the semantic tuple structure (in brackets):\\n“[We]SUBJ [evaluate]PRED [the eﬃciency and performance]DOBJ\\n[against the corpus]ADJU.”\\nIn this example, the conjunction relation connects two noun phrases, both of\\nthem being DOBJ; therefore, no new semantic tuple is necessary. However, we\\ndecided to distinguish cases where conjunction connects two sentences or verb\\nphrases. In such cases, semantic tuples are generated for each part respectively.\\nThe following example shows an AND relation. Conjunction relations may also\\nbe realized in diﬀerent lexemes, e.g. and, but, or, as well as, etc.\\nFor the sentence “The system automatically extracts pairs of syntactic units\\nfrom a text and assigns a semantic relation to each pair.”, two semantic tuples\\nare generated separately with their own PRED, DOBJ and OCMP:\\n“[The system]SUBJ [extracts]PRED [pairs of syntactic units]DOBJ\\n[from a text]OCMP [automatically]ADJU.”\\nand\\n“[The system]SUBJ [assigns]PRED [a semantic relation]DOBJ\\n[to each pair]OCMP [automatically]ADJU.”\\nIn passive sentences, the syntactic subject becomes the semantic object and\\nvice versa:\\n“[Unseen input]DOBJ [was classiﬁed]PRED [by trained neural networks\\nwith varying error rates depending corpus type]SUBJ.”\\n14\\nUlrich Sch¨afer and Bernd Kiefer\\n3.2\\nFilling the Search Index\\nFor each sentence, the semantic tuple structure together with associated char-\\nacter span information relative to the sentence start is then stored in an Apache\\nSolr5 search index. It also contains metainformation on page number, sentence\\nnumber, oﬀset and document ID.\\nIn case a named entity is identiﬁed by the named entity recognizer, further in-\\nformation on span and type (such as location, person, time) of the item is stored.\\nThis named entity type information is used to identify the answer candidate type\\nin an additional question answering interface we will not further describe in this\\npaper. The following snippet from Solr input for a single sentence may give an\\nimpression of the underlying index schema.\\n<doc>\\n<field name=\"aclaid\">N07-1043</field>\\n<field name=\"page\">2</field>\\n<field name=\"sentno\">56</field>\\n<field name=\"prefix\">N07-1043-s56-p2</field>\\n<field name=\"offset\">353</field>\\n<field name=\"qgen\">PET</field>\\n<field name=\"sentence\">Sahami et al., (2006) measure semantic\\nsimilarity between two queries using the snippets returned\\nfor those queries by a search engine.</field>\\n<field name=\"subj\">Sahami 2006 et al.</field>\\n<field name=\"subj_start\">0</field>\\n<field name=\"subj_end\">12</field>\\n<field name=\"pred\">measure</field>\\n<field name=\"pred_start\">22</field>\\n<field name=\"pred_end\">28</field>\\n<field name=\"dobj\">semantic similarity</field>\\n<field name=\"dobj_start\">30</field>\\n<field name=\"dobj_end\">48</field>\\n<field name=\"ocmp\">between two queries using the snippets\\nreturned for those queries by a search engine</field>\\n<field name=\"ocmp_start\">0</field>\\n<field name=\"ocmp_end\">133</field>\\n<field name=\"ner_types\">citation ne-term ne-term </field>\\n<field name=\"ner_cstart\">0 30 121 </field>\\n<field name=\"ner_cend\">20 48 133 </field>\\n<field name=\"ner_surface\">\"Sahami et al., (2006)\"\\n\"semantic similarity\"\\n\"search engine\" </field>\\n</doc>\\nTo sum up the overall oﬄine analysis for search index generation, Figure 8\\ndepicts the oﬄine NLP and semantic tuple extraction workﬂow.\\n5 http://lucene.apache.org/solr\\nAdvances in Deep Parsing of Scholarly Paper Content\\n15\\n Heart \\n of Gold\\n Heart \\n of Gold\\n Heart \\n of Gold\\n Heart \\n of Gold\\nsemantic tuples\\ndatabase\\nsemantic tuples\\ndatabase\\n● text cleaning\\n● XML encoding\\n● text cleaning\\n● XML encoding\\n Heart \\n of Gold\\n Heart \\n of Gold\\n Heart \\n of Gold\\n Heart \\n of Gold\\nNLP grid with \\nJTok, TnT, \\nSProUT, PET\\nsemantic tuples\\nextraction\\nsemantic tuples\\nextraction\\n+\\n+\\nscholarly papers\\n2 GB PDF\\nOCR-based\\nPDF-to-text\\nextraction \\nOCR-based\\nPDF-to-text\\nextraction \\nHeart \\nof Gold\\nHeart \\nof Gold\\nAutomatic\\nNLP XML\\nannotation\\n1 GB Apache Solr Blob (approx. 1.5 million sentences)\\nFig. 8. Grid-based hybrid parsing of the scientiﬁc paper corpus\\n3.3\\nQuery Interface\\nAs depicted in Figure 9, the user interface for semantic paper search contains\\nthree text ﬁelds where the user can input subject, predicate and all remaining\\nstructures (rest). The latter is combined to ease input (otherwise users would\\nbecome worried about what to put in OCMP or ADJU) and will be expanded\\nto a disjunctive Solr/Lucene query expression.\\nFig. 9. Simple query interface\\nTo give an example, a semantic tuple search expression with input to ﬁeld\\nsubject=*, input to ﬁeld predicate=‘measure’, and input to ﬁeld rest=‘semantic\\nsimilarity’ is translated into an Apache Solr query\\npred:measure +(dobj:\"semantic similarity\"\\n16\\nUlrich Sch¨afer and Bernd Kiefer\\nOR ocmp:\"semantic similarity\"\\nOR adju:\"semantic similarity\")\\nIn case WordNet synset [10] expansion is enabled, measure is replaced by\\n(measure OR evaluate OR quantify OR value OR assess OR valuate).\\nIt is planned to also allow for synonym search in the SUBJ and REST ﬁeld.\\nHere, domain ontology information as well as automatically identiﬁed similar\\n(multi-word) terms could be used to expand the query.\\nSearch Results for * “measure” “semantic similarity”\\n– N07-1043: Sahami et al., (2006) [measure]PRED [semantic similarity]DOBJ\\nbetween two queries using the snippets returned for those queries by a\\nsearch engine.\\n– W04-0106: [Semantic similarity]DOBJ [is measured]PRED in terms of sim-\\nilar word contexts.\\n– N07-1044: [The semantic similarity]DOBJ between neighbors and senses [is\\nmeasured]PRED using a manually crafted taxonomy such as WordNet (see\\nBudanitsky and Hirst 2001 for an overview of WordNet-based similarity\\nmeasures).\\n– P08-1028: We [assessed]PRED [a wide range of semantic similarity\\nmeasures]DOBJ using the WordNet similarity package (Pedersen et al.,\\n2004).\\n– W06-3802:\\nUsing\\nWordNet,\\nwe\\n[can\\nmeasure]PRED\\n[the\\nsemantic\\nsimilarity]DOBJ or relatedness between a pair of concepts (or word senses),\\nand by extension, between a pair of sentences.\\n– W06-1659:\\nUsing\\nWordNet,\\nwe\\n[can\\nmeasure]PRED\\n[the\\nsemantic\\nsimilarity]DOBJ or relatedness between a pair of concepts (or word senses),\\nand by extension, between a pair of sentences.\\n– W05-1203: For entailment identiﬁcation, since this is a directional relation,\\nwe [only measure]PRED [the semantic similarity]DOBJ with respect to the\\nhypothesis (the text that is entailed).\\n– W06-1104: We [measured]PRED [semantic relat-edness instead of semantic\\nsimilarity]DOBJ.\\n– P06-1112:\\n3.\\n[The\\nsemantic\\nsimilarity\\nSemSim(h\\n,\\nh\\n)]DOBJ\\n[is\\nmeasured]PRED using Word-Net and eXtended WordNet.\\n. . .\\nFig. 10. The ﬁrst matching sentences in the ACL Anthology subset 2002-2008 with\\nrecognized variation in predicate synsets (assess, measure, evaluate) and passive con-\\nstructions\\nThe result is then a list of sentence snippets (Figure 10). By clicking on a\\nhyperlink underlying the snippet text, the original PDF is opened. By using\\nthe information on page and sentence text/oﬀset in the Apache Solr answer,\\nthe result sentence is highlighted as shown in Figure 11. This helps to quickly\\nidentify relevance of the answer by looking at context in the original layout.\\nAdvances in Deep Parsing of Scholarly Paper Content\\n17\\nFig. 11. First result sentence (from N07-1043) highlighted in original PDF\\n4\\nRelated Work\\nUsing HPSG combined with shallow domain-speciﬁc modeling for high-precision\\nanalysis of scientiﬁc texts is an emerging research area. Another ERG-based\\napproach to relation and information extraction from scientiﬁc texts is SciBorg\\n[13]. SciBorg mainly deals with chemistry research papers and handles domain-\\nspeciﬁc phenomena with a specialized named entity recognizer. It relies on a\\nshallow parser as robustness fall-back for MRS generation.\\nOther groups use less elaborated and ﬁne-grained HPSG grammars than\\nERG. [11] report on large-scale parsing of MEDLINE articles (1.4 billion words)\\nwith such a simpliﬁed grammar.\\n[14] use shallow dependency structure and results from HPSG parsing for\\nextracting protein-protein interactions (PPI) from research papers. The same\\ngroup has also worked on medical texts: MEDIE6 is a semantic search engine to\\nretrieve biomedical correlations from MEDLINE articles.\\nWhat distinguishes our approach from those, besides concentration on a dif-\\nferent scientiﬁc area, is the focus on and use of ontology information as integrated\\npart of linguistic analysis, use of the most comprehensive and elaborated HPSG\\ngrammar for English (ERG), and the interactive user interface (Scientist’s Work-\\nbench application; [17]) and editor [18].\\n5\\nConclusion and Future Work\\nWe have presented our recent advances in full, robust parsing of scientiﬁc papers\\ntexts. By careful preprocessing and novel approaches to eﬃcient parsing of long\\nsentences, we could improve coverage from 65 to more than 85%.\\nThe semantic search application built on the semantic representations gen-\\nerated by the deep grammar is a useful extension to cope with synonyms and\\nsyntactic variation when querying full scientiﬁc publication content. The search\\nspace, initially expanded by adding synonymns, can be again constrained by\\nimposing semantic subject-predicate-object structure in the query.\\n6 http://www-tsujii.is.s.u-tokyo.ac.jp/medie/\\n18\\nUlrich Sch¨afer and Bernd Kiefer\\nFurther research goals are improving robustness of the NLP tool chain. We\\nare also working on generic techniques to automatically extract and use sci-\\nence domain information from the underlying paper corpus to improve targeted\\nsearch. Three main tasks in our focus are coreference resolution, term extraction\\nand ontology extraction viz. population. The idea is that these techniques, in a\\nﬁrst step gained independently from the text corpus or partially from NLP anal-\\nyses of it, will beneﬁt from each other and can be used to build more reliable\\nand precise resources and tools in a bootstrapping process.\\nHandling of negation, modal constructions, subclauses etc. also fall into the\\ncategory deep NLP can handle, but this will be addressed in the future as it also\\nrequires lexico-semantic information of verbs etc. in the extraction process. It\\nwill deﬁnitely be an important extension helping to improve precision in search.\\nThe semantic search application is part of the Scientist’s workbench and is\\ncomplemented by a visualization and navigation tool TeeCeeGeeNav [16] that\\nsupports scientists in quickly getting an overview of a (new) research ﬁeld by\\nbrowsing through a typed citation graph computed from the scientiﬁc paper\\ncorpus. The citation classiﬁcation with categories such as use or refutation of\\nresults of the cited paper currently builds on shallow NLP (such as PoS tagging)\\nonly. In the future, deep semantics could help too further improve this diﬃcult\\nclassiﬁcation task.\\nAcknowledgments\\nThe authors would like to thank Peter Adolphs, Dan Flickinger and Stephan\\nOepen for their support and numerous fruitful discussions. We would also like\\nto thank Yi Zhang and Bart Cramer for the implementation of chart pruning in\\nPET and their support to put it into use. The work described in this paper has\\nbeen carried out in the context of the project TAKE (Technologies for Advanced\\nKnowledge Extraction), funded under contract 01IW08003 by the German Fed-\\neral Ministry of Education and Research, and in the context of the world-wide\\nDELPH-IN collaboration7.\\nReferences\\n1. Adolphs, P., Oepen, S., Callmeier, U., Crysmann, B., Flickinger, D., Kiefer, B.:\\nSome ﬁne points of hybrid natural language parsing. In: Proc. of LREC. pp. 1380–\\n1387. Marrakesh, Morocco (2008)\\n2. Bird, S., Dale, R., Dorr, B., Gibson, B., Joseph, M., Kan, M.Y., Lee, D., Powley,\\nB., Radev, D., Tan, Y.F.: The ACL anthology reference corpus: A reference dataset\\nfor bibliographic research. In: Proc. of LREC. pp. 1755–1759. Marrakesh, Morocco\\n(2008)\\n3. Brants, T.: TnT – A Statistical Part-of-Speech Tagger. In: Proc. of ANLP-2000.\\npp. 224–231. Seattle, WA (2000)\\n7 DEep Linguistic Processing with Hpsg INitiative; http://www.delph-in.net\\nAdvances in Deep Parsing of Scholarly Paper Content\\n19\\n4. Callmeier, U.: PET – A platform for experimentation with eﬃcient HPSG process-\\ning techniques. Natural Language Engineering 6(1), 99–108 (2000)\\n5. Copestake, A., Flickinger, D.: An open-source grammar development environment\\nand broad-coverage English grammar using HPSG. In: Proc. of LREC. pp. 591–\\n598. Athens, Greece (2000)\\n6. Copestake, A., Flickinger, D., Sag, I.A., Pollard, C.: Minimal recursion semantics:\\nan introduction. Research on Language and Computation 3(2–3), 281–332 (2005)\\n7. Cramer, B., Zhang, Y.: Constraining robust constructions for broad-coverage pars-\\ning with precision grammars. In: Proc. of COLING. pp. 223–231. Beijing, China\\n(2010)\\n8. Dro˙zd˙zy´nski, W., Krieger, H.U., Piskorski, J., Sch¨afer, U., Xu, F.: Shallow process-\\ning with uniﬁcation and typed feature structures – foundations and applications.\\nK¨unstliche Intelligenz 2004(1), 17–23 (2004)\\n9. Flickinger, D., Oepen, S., Ytrestøl, G.: WikiWoods: Syntacto-semantic annotation\\nfor English Wikipedia. In: Proc. of LREC. pp. 1665–1671. Valletta, Malta (2010)\\n10. Miller, G.A., Beckwith, R., Fellbaum, C., Gross, D., Miller, K.J.: Five papers on\\nWordNet. Tech. rep., Cognitive Science Laboratory, Princeton University (1993)\\n11. Ninomiya, T., Tsuruoka, Y., Miyao, Y., Taura, K., Tsujii, J.: Fast and scalable\\nHPSG parsing. Traitement automatique des langues (TAL) 46(2) (2006)\\n12. Pollard, C., Sag, I.A.: Head-Driven Phrase Structure Grammar. Studies in Con-\\ntemporary Linguistics, University of Chicago Press, Chicago (1994)\\n13. Rupp, C., Copestake, A., Corbett, P., Waldron, B.: Integrating general-purpose\\nand domain-speciﬁc components in the analysis of scientiﬁc text. In: Proc. of the\\nUK e-Science Programme All Hands Meeting 2007. Nottingham, UK (2007)\\n14. Sætre, R., Kenji, S., Tsujii, J.: Syntactic features for protein-protein interaction\\nextraction. In: Baker, C.J., Jian, S. (eds.) Short Paper Proc. of the 2nd Int. Symp.\\non Languages in Biology and Medicine (LBM 2007). pp. 6.1–6.14. Singapore (2008)\\n15. Sch¨afer, U.: Middleware for creating and combining multi-dimensional NLP\\nmarkup. In: Proc. of the EACL-2006 Workshop on Multi-dimensional Markup in\\nNatural Language Processing. pp. 81–84. Trento, Italy (2006)\\n16. Sch¨afer, U., Kasterka, U.: Scientiﬁc authoring support: A tool to navigate in typed\\ncitation graphs. In: Proc. of the NAACL-HLT 2010 Workshop on Computational\\nLinguistics and Writing. pp. 7–14. Los Angeles, CA (2010)\\n17. Sch¨afer, U., Spurk, C.: TAKE Scientist’s Workbench: Semantic search and citation-\\nbased visual navigation in scholar papers. In: Proc. of the 4th IEEE Int. Conference\\non Semantic Computing (ICSC-2010). pp. 317–324. Pittsburgh, PA (2010)\\n18. Sch¨afer, U., Uszkoreit, H., Federmann, C., Marek, T., Zhang, Y.: Extracting and\\nquerying relations in scientiﬁc papers. In: Proc. of the 31st Annual German Confer-\\nence on Artiﬁcial Intelligence (KI-2008). pp. 127–134. Springer LNAI 5243 (2008)\\n')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4f0bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_chunks = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c632b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Advances in Deep Parsing of Scholarly Paper\\nContent\\nUlrich Sch¨afer and Bernd Kiefer\\nLanguage Technology Lab\\nGerman Research Center for Artiﬁcial Intelligence (DFKI)\\nCampus D3 1, D-66123 Saarbr¨ucken, Germany\\n{ulrich.schaefer,kiefer}@dfki.de\\nhttp://www.dfki.de/lt\\nAbstract. We report on advances in deep linguistic parsing of the full\\ntextual content of 8200 papers from the ACL Anthology, a collection of\\nelectronically available scientiﬁc papers in the ﬁelds of Computational\\nLinguistics and Language Technology.\\nWe describe how – by incorporating new techniques – we increase both\\nspeed and robustness of deep analysis, speciﬁcally on long sentences'),\n",
       " Document(metadata={}, page_content='We describe how – by incorporating new techniques – we increase both\\nspeed and robustness of deep analysis, speciﬁcally on long sentences\\nwhere deep parsing often failed in former approaches. With the current\\nopen source HPSG (Head-driven phrase structure grammar) for English\\n(ERG), we obtain deep parses for more than 85% of the sentences in the\\n1.5 million sentences corpus, while the former approaches achieved only\\napprox. 65% coverage.\\nThe resulting sentence-wise semantic representations are used in the Sci-\\nentist’s Workbench, a platform demonstrating the use and beneﬁt of\\nnatural language processing (NLP) to support scientists or other knowl-'),\n",
       " Document(metadata={}, page_content='entist’s Workbench, a platform demonstrating the use and beneﬁt of\\nnatural language processing (NLP) to support scientists or other knowl-\\nedge workers in fast and better access to digital document content. With\\nthe generated NLP annotations, we are able to implement important,\\nnovel applications such as robust semantic search, citation classiﬁcation,\\nand (in the future) question answering and deﬁnition exploration.\\n1\\nIntroduction\\nScientists in all disciplines are nowadays faced with a ﬂood of new publications\\nevery day. In addition, more and more publications from the past become dig-\\nitally available and thus even increase the amount of data. Therefore, ﬁnding'),\n",
       " Document(metadata={}, page_content='itally available and thus even increase the amount of data. Therefore, ﬁnding\\nrelevant information and avoiding redundancy and duplication of work have be-\\ncome urgent issues to be addressed by the scientiﬁc community.\\nThe organization and preservation of scientiﬁc knowledge in scientiﬁc pub-\\nlications, vulgo text documents, thwarts these eﬀorts. From a viewpoint of a\\ncomputer scientist, scientiﬁc papers are just ‘unstructured information’.\\nAutomatically precomputed, normalized semantic representations of textual\\nutterances could help to structure the search space and ﬁnd equivalent or related\\npropositions even if they are expressed diﬀerently, e.g. in passive constructions,'),\n",
       " Document(metadata={}, page_content='propositions even if they are expressed diﬀerently, e.g. in passive constructions,\\nusing synonyms etc. Domain-relevant semantic similarity can be computed auto-\\nmatically and exploited as additional knowledge source to support robust search.\\n⋆Pre-print. The original publication is available at http://www.springerlink.com.\\n2\\nUlrich Sch¨afer and Bernd Kiefer\\nTo again constrain the so expanded search space, users can ask the system\\nin simply structured subject-predicate-object queries and get all matching, pre-\\ncomputed predicate-argument structures along with the original sentence from\\nthe paper. On the other hand, by storing the structure along with the original'),\n",
       " Document(metadata={}, page_content='the paper. On the other hand, by storing the structure along with the original\\ntext in a structured full-text search engine such as Apache Lucene, it can be\\nguaranteed that recall cannot fall behind the baseline of a fulltext search engine.\\nThe basis of our scientiﬁc paper corpus is a subset of the ACL Anthology1,\\na collection of conference and workshop papers in the ﬁeld of Computational\\nLinguistics and Language Technology. We concentrate on 8200 papers from the\\nyears 2002 through 2009 from which we extracted the textual content using\\nAbbyy PDF Transformer.\\nExcept for named entity recognition which is partly based on instances and'),\n",
       " Document(metadata={}, page_content='Abbyy PDF Transformer.\\nExcept for named entity recognition which is partly based on instances and\\nconcepts of a domain ontology, the processing pipeline we describe below is\\nindependent of the science domain.\\nTo make the deep parser robust, it is embedded in a hybrid NLP workﬂow\\nstarting with a tokenizer, a part-of-speech tagger, and a named entity recognizer.\\nThese components help to identify and classify open class words such as person\\nnames, events (e.g. conferences) or locations. The trigram-based tagger helps\\nto guess part-of-speech tags of words unknown to the deep lexicon. For both\\nunknown words and named entities, generic lexicon entries are generated in the'),\n",
       " Document(metadata={}, page_content='unknown words and named entities, generic lexicon entries are generated in the\\ndeep parser running the open source broad-coverage grammar ERG [5].\\nIn contrast to shallow parsers, the ERG not only handles detailed syntac-\\ntic analyses of phrases, compounds, coordination, negation and other linguistic\\nphenomena that are important for extracting semantic relations, but also gen-\\nerates a formal semantic representation of the meaning of the input sentence in\\nthe MRS (Minimal Recursion Semantics; [6]) representation format. Ambiguities\\nresulting in multiple readings per input sentence are ranked using a statistical\\nparse ranking model.'),\n",
       " Document(metadata={}, page_content='resulting in multiple readings per input sentence are ranked using a statistical\\nparse ranking model.\\nIn an earlier experiment, we obtained full deep parses for 64.89% of 955,581\\nsentences and 35.11% of the sentences were parsed by a fall-back shallow parser.\\nOnly 0.24% of the sentences could not be parsed at all.\\nIn this chapter, we describe the ﬁne-grained mapping of punctuation and\\nother tokenization details by means of a chart mapping technique [1] ensuring\\nthat this information is now optimally used by the deep grammar for disambigua-\\ntion. We also report on progress that we achieved by applying a chart pruning'),\n",
       " Document(metadata={}, page_content='tion. We also report on progress that we achieved by applying a chart pruning\\ntechnique [7] that, as already proven on another corpus, helps to considerably\\nincrease parsing speed of the deep parser and the number of successfully parsed\\nsentences. With both techniques applied together, we could not only increase\\nparsing speed considerably, but also the coverage on the ACL Anthology corpus\\nto more than 85%.\\nThis chapter is structured as follows. In section 2, we present the improved\\nparsing approach and results. In Section 3, we describe the semantic search\\napplication based on the improved parsing results. Section 4 discusses related'),\n",
       " Document(metadata={}, page_content='application based on the improved parsing results. Section 4 discusses related\\nwork, and we ﬁnally conclude and give an outlook to future work in Section 5.\\n1 http://www.aclweb.org/anthology\\nAdvances in Deep Parsing of Scholarly Paper Content\\n3\\n2\\nDeep Parsing of Scholarly Papers\\nThe general idea of the semantics-oriented access to scholarly paper content is\\nto apply NLP analysis to each sentence they contain and distill a structured\\nrepresentation that can be searched for in addition to fulltext. Diﬀerent levels of\\nanalysis such as part-of-speech (PoS) tagging, named entity recognition (NER),\\nchunking, shallow and deep parsing are suitable for diﬀerent tasks.'),\n",
       " Document(metadata={}, page_content='analysis such as part-of-speech (PoS) tagging, named entity recognition (NER),\\nchunking, shallow and deep parsing are suitable for diﬀerent tasks.\\nWhile citation sentence classiﬁcation in scholarly papers, a further applica-\\ntion described in [16], is currently based on shallow NLP tasks such as tokeniza-\\ntion, PoS tagging and patterns thereof only, the semantic search application is\\nbased on the full range of hybrid, robustness-oriented NLP. This includes shal-\\nlow preprocessing with statistical taggers up to full deep parsing with generation\\nof sentence semantics representations from which basically predicate-argument'),\n",
       " Document(metadata={}, page_content='of sentence semantics representations from which basically predicate-argument\\nstructure is derived. Thus, both applications share the preprocessing, and in the\\nfuture, also citation sentence classiﬁcation could make use of linguistic features\\nextracted by more advanced NLP.\\n2.1\\nThe Corpus\\nThe basis of our scientiﬁc paper corpus is a subset of the ACL Anthology [2],\\na collection of conference and workshop papers in the ﬁeld of Computational\\nLinguistics and Language Technology. We concentrate on 8200 papers from the\\nyears 2002 through 2009 available in a native PDF format, i.e. not optically\\nscanned at limited quality such as many older papers. Except for named entity'),\n",
       " Document(metadata={}, page_content='scanned at limited quality such as many older papers. Except for named entity\\nrecognition which is partly based an a domain ontology, the processing pipeline\\nwe describe below is independent of the science domain. However, we expect\\nimprovements in the future by modeling domain knowledge, e.g. through auto-\\nmatically extracted domain speciﬁc terms and ontology concepts.\\n2.2\\nPDF Extraction\\nThe preprocessing step starts extracting clean text from the digital PDF docu-\\nments. In a ﬁrst version, we used PDFBox2 to gain raw text content from the\\npapers. This works well for most (especially recent) papers. However, it is prob-'),\n",
       " Document(metadata={}, page_content='papers. This works well for most (especially recent) papers. However, it is prob-\\nlematic in general because PDFBox relies on the logical, digital content of the\\npage (layout) description language PDF. Its internal structure is very much de-\\npendent on the tool that was used to generate the PDF, and there are many tools\\nand of varying quality. Thus, decoding text from it does not work 100% correctly,\\nand imposes severe problems up to complete garbage because of non-standard\\ncharacter encodings or no output on about 10% of the corpus.\\nTo overcome these problems and become independent of the PDF encoder\\nthat was used to generate the digital paper, we recently moved to OCR-based'),\n",
       " Document(metadata={}, page_content='To overcome these problems and become independent of the PDF encoder\\nthat was used to generate the digital paper, we recently moved to OCR-based\\nPDF extraction with the commercial product Abbyy PDF Transformer3. It also\\n2 http://pdfbox.apache.org\\n3 http://www.abbyy.com\\n4\\nUlrich Sch¨afer and Bernd Kiefer\\nreliably resolves hyphenated words using its own language model as well as text\\n(order) in tables. Moreover, and in contrast to PDFBox, it also works on scanned\\ndocuments, provided that the scan quality is good enough. However, recognition\\nof non-Latin characters such as in mathematical formulae remains a problem.\\nIt can be ignored for the time being because the NLP tools used also do not'),\n",
       " Document(metadata={}, page_content='It can be ignored for the time being because the NLP tools used also do not\\nunderstand mathematics.\\nAfter text extraction, a sentence splitter segments into sentence units in order\\nto provide suitable input for subsequent NLP. For each sentence, we record a\\nunique document ID (in case of our corpus the ACL Anthology paper ID, e.g.\\nC02-1023 for a paper from the COLING-2002 proceedings), the page on which\\nit appeared, and the sentence number relative to the whole document. Amongst\\nothers, this information is important to highlight a search result or citation\\nsentence within the original PDF paper layout.\\n2.3\\nHybrid Parsing\\nTo make the deep parser robust, it is embedded in a hybrid NLP workﬂow'),\n",
       " Document(metadata={}, page_content='sentence within the original PDF paper layout.\\n2.3\\nHybrid Parsing\\nTo make the deep parser robust, it is embedded in a hybrid NLP workﬂow\\nimplemented using the hybrid NLP platform Heart of Gold [15]. Heart of Gold\\nis an XML-based middleware architecture for the integration of multilingual\\nshallow and deep natural language processing components, developed under the\\numbrella of the DELPH-IN initiative4.\\nThe employed Heart of Gold conﬁguration instance starts with a tokenizer,\\nthe shallow part-of-speech tagger TnT [3] and the named entity recognizer\\nSProUT [8]. These components help to identify and classify open class words\\nsuch as person names, events (e.g. conferences) or locations.'),\n",
       " Document(metadata={}, page_content='SProUT [8]. These components help to identify and classify open class words\\nsuch as person names, events (e.g. conferences) or locations.\\nThe (trigram-based) tagger helps to guess part-of-speech tags of words un-\\nknown to the deep lexicon. For both unknown words and named entities, generic\\nlexicon entries are generated in the deep parser. By means of the PET input\\nchart XML format FSC [1], the shallow preprocessing results are combined and\\npassed to the high-speed HPSG [12] parser PET [4] running the open source\\nbroad-coverage grammar ERG [5] (cf. Fig 2).\\n2.4\\nPrecise Preprocessing Integration with Chart Mapping\\nChart mapping [1] is a novel mechanism for the non-monotonic, rule-based ma-'),\n",
       " Document(metadata={}, page_content='2.4\\nPrecise Preprocessing Integration with Chart Mapping\\nChart mapping [1] is a novel mechanism for the non-monotonic, rule-based ma-\\nnipulation of chart items that are described by feature structures. There are\\ncurrently two chart mapping phases in PET during parsing: (1) Token map-\\nping, where input items as delivered by external preprocessors are adapted to\\nthe expectations of the grammar. This requires that input items are described\\nby feature structures – the token feature structures. (2) Lexical ﬁltering, where\\nlexical items can be ﬁltered by hard constraints after lexical parsing has ﬁnished.\\nToken mapping requires tokens to be described by feature structures. Token'),\n",
       " Document(metadata={}, page_content='Token mapping requires tokens to be described by feature structures. Token\\nfeature structures can be arbitrarily complex. This allows users to pass informa-\\ntion of various preprocessing modules into the parser. To this end, a new format,\\nthe XML-based FSC input format, was developed.\\n4 http://www.delph-in.net/heartofgold/\\nAdvances in Deep Parsing of Scholarly Paper Content\\n5\\nFollowing is an excerpt from the FSC for the sentence “Resnik and Smith\\n(2003) extract bilingual sentences from the Web to create parallel corpora for\\nmachine translation.” (from anthology document N07-1043) generated by Heart\\nof Gold preprocessing from TnT and SProUT output.\\n<fsc version=\"1.0\">'),\n",
       " Document(metadata={}, page_content='machine translation.” (from anthology document N07-1043) generated by Heart\\nof Gold preprocessing from TnT and SProUT output.\\n<fsc version=\"1.0\">\\n<chart id=\"hog://session1284321397757/collection1/TnT\">\\n<lattice init=\"v0\" final=\"v20\">\\n<edge source=\"v0\" target=\"v1\">\\n<fs type=\"token\">\\n<f name=\"+FORM\"><str>Resnik</str></f>\\n<f name=\"+FROM\"><str>0</str></f>\\n<f name=\"+TO\"><str>6</str></f>\\n<f name=\"+TNT\">\\n<fs type=\"tnt\">\\n<f name=\"+TAGS\" org=\"list\"><str>NNP</str></f>\\n<f name=\"+PRBS\" org=\"list\"><str>1.000000</str></f>\\n</fs>\\n</f>\\n</fs>\\n</edge>\\n... <!-- more token edges from TnT -->\\n<edge source=\"v6\" target=\"v7\">\\n<fs type=\"token\">\\n<f name=\"+FORM\"><str>extract</str></f>\\n<f name=\"+FROM\"><str>24</str></f>'),\n",
       " Document(metadata={}, page_content='<edge source=\"v6\" target=\"v7\">\\n<fs type=\"token\">\\n<f name=\"+FORM\"><str>extract</str></f>\\n<f name=\"+FROM\"><str>24</str></f>\\n<f name=\"+TO\"><str>31</str></f>\\n<f name=\"+TNT\">\\n<fs type=\"tnt\">\\n<f name=\"+TAGS\" org=\"list\"><str>VB</str></f>\\n<f name=\"+PRBS\" org=\"list\"><str>1.000000</str></f>\\n</fs>\\n</f>\\n</fs>\\n</edge>\\n... <!-- more token edges from TnT -->\\n<!-- this edge comes from the Named Entity Recognizer -->\\n<edge source=\"v0\" target=\"v6\">\\n<fs type=\"token\">\\n<f name=\"+FORM\"><str>Resnik and Smith (2003)</str></f>\\n<f name=\"+FROM\"><str>0</str></f>\\n<f name=\"+TO\"><str>23</str></f>\\n<f name=\"+TNT\"><fs type=\"null_tnt\"/></f>\\n<f name=\"+CLASS\"><fs type=\"proper_ne\"/></f>'),\n",
       " Document(metadata={}, page_content='<f name=\"+FROM\"><str>0</str></f>\\n<f name=\"+TO\"><str>23</str></f>\\n<f name=\"+TNT\"><fs type=\"null_tnt\"/></f>\\n<f name=\"+CLASS\"><fs type=\"proper_ne\"/></f>\\n<f name=\"+TRAIT\"><fs type=\"generic_trait\"/></f>\\n</fs>\\n</edge>\\n</lattice>\\n</chart>\\n</fsc>\\n6\\nUlrich Sch¨afer and Bernd Kiefer\\nFigure 1 shows how tokenized and PoS-tagged input is combined with pos-\\nsibly concurrent information from a named entity recognizer, in the example\\nSProUT delivering hypothetical information on named entities (here a citation\\nstring) in a single named entity item spanning over multiple words.\\nConcerning punctuation, the deep grammar can e.g. make use of information'),\n",
       " Document(metadata={}, page_content='string) in a single named entity item spanning over multiple words.\\nConcerning punctuation, the deep grammar can e.g. make use of information\\non opening and closing quotation marks. This information is often not explicit\\nin the input text, e.g. when gained through OCR techniques, which make no\\ndistinction between ‘ and ’ or “ and ”. However, a tokenizer can often guess\\n(reconstruct) leftness and rightness correctly. This information, passed to the\\ndeep parser via FSC, helps it to disambiguate.\\nv0\\nv1\\nFORM Resnik\\nFROM\\n0\\nTO\\n6\\nTNT\\nNNP\\nv6\\nFORM Resnik and Smith (2003)\\nFROM\\n0\\nTO\\n23\\nCLASS\\nproper_ne\\nv2\\nFORM and\\nFROM\\n7\\nTO\\n10\\nTNT\\nCC\\nv3\\nFORM Smith\\nFROM\\n11\\nTO\\n16\\nTNT\\nNNP\\nv4\\nFORM\\n(\\nFROM 17\\nTO\\n18\\nTNT\\n(\\nv5'),\n",
       " Document(metadata={}, page_content='FROM\\n0\\nTO\\n23\\nCLASS\\nproper_ne\\nv2\\nFORM and\\nFROM\\n7\\nTO\\n10\\nTNT\\nCC\\nv3\\nFORM Smith\\nFROM\\n11\\nTO\\n16\\nTNT\\nNNP\\nv4\\nFORM\\n(\\nFROM 17\\nTO\\n18\\nTNT\\n(\\nv5\\nFORM 2003\\nFROM\\n18\\nTO\\n22\\nTNT\\nCD\\nFORM\\n)\\nFROM 22\\nTO\\n23\\nTNT\\n)\\nFig. 1. FSC input to PET with combined information from tokenizer, PoS tagger and\\nconcurrent SProUT citation string item for input fragment “Resnik and Smith (2003)\\nextract ...”\\nFurthermore, a new way of generic lexical instantiation has been introduced\\nwith token feature structures and chart mapping. In this new setup, the parser\\ntries to instantiate all generic lexical entries for each word. Upon lexical instan-\\ntiation, the token feature is uniﬁed into a designated path of the lexical entry.'),\n",
       " Document(metadata={}, page_content='tiation, the token feature is uniﬁed into a designated path of the lexical entry.\\nOnly if this uniﬁcation succeeds, the lexical item is instantiated. In order to con-\\ntrol the instantiation of generic lexical entries, the token feature structures are\\nappropriately constrained in the generic lexical entry, for instance by requiring\\nthat a generic verbal entry is only applicable for token feature structures where\\nthe highest ranked part-of-speech tag is a verb.\\n2.5\\nIncreased Processing Speed and Coverage through Chart\\nPruning\\nThe use of statistical models for result selection is well established for parsing\\nwith PET and ERG. We use a discriminative maximum entropy model based on'),\n",
       " Document(metadata={}, page_content='with PET and ERG. We use a discriminative maximum entropy model based on\\nWeScience data [9] to compute the best parse results. Recently, [7] described the\\nuse of a generative model to increase eﬃciency by shaping the search space of\\nthe parser towards the more likely constituents and pruning very unlikely ones.\\nThis method not only results in lower parse times, but also in slightly better\\ncoverage, since sentences which could not be parsed due to timeouts now ﬁt into\\nthe given time bounds.\\nThe generative model is in fact a probabilistic context-free grammar (PCFG)\\ncomputed from the same tree banks as the discriminative model. The parser in'),\n",
       " Document(metadata={}, page_content='computed from the same tree banks as the discriminative model. The parser in\\nPET is a straightforward bottom-up chart parser with agenda, which makes it\\nAdvances in Deep Parsing of Scholarly Paper Content\\n7\\ninput\\nsentence\\ninput\\nsentence\\ntokenizer\\ntokenizer\\nPoS tagger\\nPoS tagger\\nnamed entity\\nrecognizer\\nnamed entity\\nrecognizer\\nPET parser\\nPET parser\\nPET XML\\ninput chart\\nPET XML\\ninput chart\\nMRX\\nMRX\\nsemantic tuples\\ndatabase\\nsemantic tuples\\ndatabase\\nsemantic tuples extractor\\nsemantic tuples extractor\\nFig. 2. Heart of Gold workﬂow for hybrid parsing and semantic tuples extraction\\neasy to use a model that has only local dependencies, such as PCFG. What'),\n",
       " Document(metadata={}, page_content='easy to use a model that has only local dependencies, such as PCFG. What\\nis missing is a heuristics to prune unlikely items in a way that has a small\\ncomputation overhead and will retain most of the items that are needed for the\\nglobally best results.\\n[11] did a very thorough comparison of diﬀerent performance optimization\\nstrategies, and among those also a local pruning strategy which is similar to the\\none used by [7]. It restricts the number of items given both their length and start\\npoint in the chart. This is easy to implement and avoids the use of complicated\\nheuristics to compensate the bias that shorter items become over longer chart'),\n",
       " Document(metadata={}, page_content='heuristics to compensate the bias that shorter items become over longer chart\\nitems because of decreasing probability, which leads, without compensation, to\\na breadth-ﬁrst strategy for the whole parse. The number of items per chart cell\\nis restricted to a ﬁxed number to hinder the parser from getting lost in local\\nprobability maxima.\\nThere is an important diﬀerence to the system of [11], namely that their\\nsystem works on a reduced context-free backbone of the grammar and then\\nreconstructs the full results, while PET uses the full HPSG grammar directly,\\n8\\nUlrich Sch¨afer and Bernd Kiefer\\nwith subsumption packing and partial unpacking to achieve a similar eﬀect as'),\n",
       " Document(metadata={}, page_content='8\\nUlrich Sch¨afer and Bernd Kiefer\\nwith subsumption packing and partial unpacking to achieve a similar eﬀect as\\nthe packed chart of a context-free parser.\\nThe local chart pruning results in a measurable speed-up with a negligible\\ndecrease in parsing accuracy; in fact, an increase in f-measure has been observed\\nbecause complicated sentences that had originally failed due to resource restric-\\ntions could now be parsed.\\n 0\\n 10\\n 20\\n 30\\n 40\\n 50\\n 60\\n 70\\n 80\\n 0\\n 20\\n 40\\n 60\\n 80\\n 100\\nsentences x 1000\\nmean parse time (CPU s)\\nsentence length −→\\nFig. 3. Distribution of sentence length and mean parse times for mild pruning\\nProcessing Results. In total, we parsed 1,537,801 sentences, of which 57,832'),\n",
       " Document(metadata={}, page_content='Processing Results. In total, we parsed 1,537,801 sentences, of which 57,832\\n(3.8%) could not be parsed because of lexicon errors which are mostly due to\\nOCR artifacts.\\nFigure 3 displays the average parse time of processing with moderate chart\\npruning, together with the mean quadratic error. In addition, it contains the\\ndistribution of input sentences over sentence length. Obviously, the vast majority\\nof sentences has a length up to 60 words maximum.\\nParse time was limited to 60 CPU seconds, and main memory consumption\\nto 4 GB, which was far more than ever needed by the processes. Overall, the\\nparse times only grow mildly due to the many optimization techniques in the'),\n",
       " Document(metadata={}, page_content='parse times only grow mildly due to the many optimization techniques in the\\noriginal system, and also the new chart pruning method. The sentence length\\ndistribution has been integrated into Figure 3 to show that the predominant part\\nof our real-world corpus can be processed using this information-rich method\\nwith very modest parse times.\\nThe large amount of short inputs is at ﬁrst surprising, moreover as most of\\nthese inputs can not be parsed, as can be seen in Figure 5. The explanation\\nAdvances in Deep Parsing of Scholarly Paper Content\\n9\\nis easy: most of these inputs are non-sentences such as headings, enumerations,'),\n",
       " Document(metadata={}, page_content='Advances in Deep Parsing of Scholarly Paper Content\\n9\\nis easy: most of these inputs are non-sentences such as headings, enumerations,\\nfootnotes and such. How we deal with this kind of input will be described in the\\nsection about fragmentary input.\\nAll measurements were carried out on an Intel XEON E5430 2.66GHz cluster\\ncomputer. Except for the parallelization, the used hardware equals a modern\\nstandard desktop PC, which again shows the feasibility of the used method.\\n 0\\n 10\\n 20\\n 30\\n 40\\n 50\\n 60\\n 0\\n 20\\n 40\\n 60\\n 80\\n 100\\nno pruning\\nmax400\\nmax100\\nsentence length −→\\nMean parse time (CPU sec) over sentence length\\nNo pruning\\nMax. 400 passive Max. 100 passive\\nAvg. Parse Time (CPU sec)\\n5.90\\n3.95\\n2.17'),\n",
       " Document(metadata={}, page_content='Mean parse time (CPU sec) over sentence length\\nNo pruning\\nMax. 400 passive Max. 100 passive\\nAvg. Parse Time (CPU sec)\\n5.90\\n3.95\\n2.17\\nUnparsed Sentences\\n433104 (28.2%) 392758 (25.5%)\\n381019 (24.8%)\\nRecall\\n71.8%\\n74.5%\\n75.2%\\nBest Parse Lost\\n5.43%\\n19.7%\\nFig. 4. Comparison of results with diﬀerent chart pruning settings\\nFigure 4 shows the eﬀects of the chart pruning approach using moderate\\nas well as more aggressive pruning. The last row displays the amount of parsed\\nsentences which do not get the best results due to pruning. Note that the increase\\nin parsed sentences is only due to the reduced resource needs through pruning,'),\n",
       " Document(metadata={}, page_content='in parsed sentences is only due to the reduced resource needs through pruning,\\nand that the lexical failures are not contained in the unparsed sentences ﬁgures.\\nFigure 5 shows the amount of unparsed sentences, split into two categories.\\nThe dots represent the sentences that could not be parsed due to time limitations,\\nthe solid lines those that were rejected by the grammar. Not surprisingly, the\\nfraction of sentences hitting the time bound increases noticeably for sentences\\n10\\nUlrich Sch¨afer and Bernd Kiefer\\nlonger that 60 words, but it should be noted that the percentage that can not\\nbe parsed because of grammatical reasons stays almost constant.\\n 0\\n 10\\n 20\\n 30\\n 40\\n 50\\n 60\\n 70\\n 80\\n 90'),\n",
       " Document(metadata={}, page_content='be parsed because of grammatical reasons stays almost constant.\\n 0\\n 10\\n 20\\n 30\\n 40\\n 50\\n 60\\n 70\\n 80\\n 90\\n 100\\n 0\\n 20\\n 40\\n 60\\n 80\\n 100\\nno pruning\\nno pruning timeout\\ncp400\\ncp400 timeout\\ncp100\\ncp100 timeout\\nsentence length −→\\nFig. 5. Percentage of unparsed sentences over sentence length\\nFor sentences with less than 40 words, aggressive chart pruning loses parses\\n(around 0.8%) that the mild pruning still does successfully, because edges needed\\nfor a full parse are pruned from the chart. In toto, the aggressive pruning gets\\nmore readings because it greatly improves recall on the longer sentences, but\\nsome are lost in the important middle range, which is also why we use the'),\n",
       " Document(metadata={}, page_content='some are lost in the important middle range, which is also why we use the\\nresults from the mild pruning for the extraction of the semantics. An advanced\\nsystem could adapt pruning to the input length, or try to come up with better\\nlocal models that minimize the loss of useful subconstituents.\\nWe also compared the (absolute) scores of the discriminative model for the\\ntwo variants. While the method without chart pruning always ﬁnds the best\\nparse, this is not true for the pruned chart. The result is displayed in the fourth\\nrow of the table in Figure 4. Since the scores of the maximum entropy model\\nare not probabilities, we can not give meaningful numbers on the loss of quality,'),\n",
       " Document(metadata={}, page_content='are not probabilities, we can not give meaningful numbers on the loss of quality,\\nbut a rough comparison of the scores suggests that in most cases the penalty is\\nminor.\\nFragmentary Input. There are several alternatives to deal with input like\\nheadings and footnotes, one to identify and handle them in a preprocessing\\nstep, another to use a special root condition in the deep analysis component\\nthat is able to combine phrases with well-deﬁned properties for inputs where no\\nspanning result could be found.\\nAdvances in Deep Parsing of Scholarly Paper Content\\n11\\nWe employed the second method, which has the advantage that it handles a'),\n",
       " Document(metadata={}, page_content='Advances in Deep Parsing of Scholarly Paper Content\\n11\\nWe employed the second method, which has the advantage that it handles a\\nlarger range of phenomena in a homogeneous way. Figure 6 shows the change in\\npercentage of unparsed and timed out inputs for the mild pruning method with\\nand without the root condition combining fragments.\\n 0\\n 10\\n 20\\n 30\\n 40\\n 50\\n 60\\n 70\\n 80\\n 90\\n 100\\n 0\\n 20\\n 40\\n 60\\n 80\\n 100\\nstrict\\nstrict timeout\\nstrict+fragments\\nstrict+fragments timeout\\nsentence length −→\\nFig. 6. Unparsed and timed out sentences with and without fragment combination\\nAs Figure 6 shows nicely, this changes the curve for unparsed sentences to-'),\n",
       " Document(metadata={}, page_content='As Figure 6 shows nicely, this changes the curve for unparsed sentences to-\\nwards more expected characteristics and removes the uncommonly high percent-\\nage of short sentences for which no parse can be found.\\nTogether with the parses for fragmented input, we get a recall (sentences\\nwith at least one parse) over the whole corpus of 85.9% (1,321,336 sentences),\\nwithout a signiﬁcant change for any of the other numbers.\\n2.6\\nParser Output\\nIn contrast to shallow parsers, the ERG not only handles detailed syntactic\\nanalyses of phrases, compounds, coordination, negation and other linguistic phe-\\nnomena that are important for extracting relations, but also generates a formal'),\n",
       " Document(metadata={}, page_content='nomena that are important for extracting relations, but also generates a formal\\nsemantic representation of the meaning of the input sentence in the MRS repre-\\nsentation format (Minimal Recursion Semantics; [6]). It is comparable to a ﬁrst\\norder logic form. It consists of so-called elementary predications for each token\\nand larger constituents, connected via argument positions and variables/labels,\\nfrom which the predicate-argument structure can be derived (example in Fig-\\nure 7).\\n12\\nUlrich Sch¨afer and Bernd Kiefer\\n⟨h1,\\nh3:udef q(x5{PERS 3, NUM sg}, h4, h6),\\nh7: semantic a 1(e8{SF prop, TENSE untensed, MOOD indicative}, x5),\\nh7: similarity n to(x5, i9),'),\n",
       " Document(metadata={}, page_content='⟨h1,\\nh3:udef q(x5{PERS 3, NUM sg}, h4, h6),\\nh7: semantic a 1(e8{SF prop, TENSE untensed, MOOD indicative}, x5),\\nh7: similarity n to(x5, i9),\\nh10: measure v 1(e2{SF prop, TENSE pres, MOOD indicative, PROG -, PERF -}, p11, x5),\\nh10:parg d(e12{SF prop}, e2, x5),\\nh10: in p(e13{SF prop, TENSE untensed, MOOD indicative}, e2, x14{PERS 3, NUM pl, IND +}),\\nh15:udef q(x14, h16, h17),\\nh18: term n of(x14, x19{PERS 3, NUM pl}),\\nh20:udef q(x19, h21, h22),\\nh23:compound(e25{SF prop, TENSE untensed, MOOD indicative, PROG -, PERF -}, x19, x24),\\nh26:udef q(x24, h27, h28),\\nh29: similar a to(e30{SF prop, TENSE untensed, MOOD indicative}, x24),\\nh29:comp(e32{SF prop}, e30, u31),\\nh29: word n of(x24, i33),'),\n",
       " Document(metadata={}, page_content='h29: similar a to(e30{SF prop, TENSE untensed, MOOD indicative}, x24),\\nh29:comp(e32{SF prop}, e30, u31),\\nh29: word n of(x24, i33),\\nh23: context n 1(x19)\\n{ h27 =q h29, h21 =q h23, h16 =q h18, h4 =q h7 } ⟩\\nFig. 7. Sample MRS for the sentence “Semantic similarity is measured in terms of\\nsimilar word contexts.”\\nAs in previous work [18] and because of the increased parsing recall, we again\\nopt for precision and only use results from the deep parser instead of extending\\nthe hybrid workﬂow (Figure 2) in such a way that a shallow parser with less\\ndetailed analyses is used as fall-back in case deep parsing fails (as done in an\\nintermediate system, [17]).\\n3'),\n",
       " Document(metadata={}, page_content='detailed analyses is used as fall-back in case deep parsing fails (as done in an\\nintermediate system, [17]).\\n3\\nApplication: Semantic Search Based on Extracted\\nPredicate-Argument Structure\\nThe idea of the semantic search application is to use the sentence-wise semantic\\nrepresentations generated oﬄine by the deep parser. From its output, a normal-\\nized predicate-argument structure is extracted that is stored in a search index.\\nThe main motivation is at least partial abstraction from syntactic variants. Thus,\\nthe extraction process includes dividing sentences with coordination into inde-\\npendent structures, and using the semantic subject and object in both active'),\n",
       " Document(metadata={}, page_content='pendent structures, and using the semantic subject and object in both active\\nand passive sentence construction independently of the syntactic realization.\\nThe user interface for this application is simple. Instead of a single search text\\ninput ﬁeld, the user will see three: one for subject, one for predicate and another\\none for further objects. This is easy to understand also for non-linguists, and\\nﬁelds may be left emtpy to match anything. In the current version, the search\\ninterface supports the use of synsets of predicates only.\\n3.1\\nExtracting Predicate-Argument Structure from MRS\\nThe MRS representations resulting from hybrid parsing are relatively close to'),\n",
       " Document(metadata={}, page_content='3.1\\nExtracting Predicate-Argument Structure from MRS\\nThe MRS representations resulting from hybrid parsing are relatively close to\\nlinguistic structures and contain more detailed information than a user would\\nAdvances in Deep Parsing of Scholarly Paper Content\\n13\\nlike to query and search for. Therefore, an additional extraction and abstraction\\nstep is necessary before storing the semantic structures in the search index.\\nThe format we devised for this purpose we call semantic tuples, a blend of\\ntriples and quintuples, as we store quintuples (subject, predicate, direct object,\\nother complements and adjunct), but to ease search term input for the user, only'),\n",
       " Document(metadata={}, page_content='other complements and adjunct), but to ease search term input for the user, only\\ndistinguish between a triple of subject, predicate and any other objects in the\\nquery structure.\\nThe algorithm to generate the semantic tuples ﬁrst performs an intermedi-\\nate transformation into isomorphic, serializable Java objects that can be made\\npersistent. On these objects, eﬃcient graph manipulation resulting in extracted\\nsemantic tuples can take place. Handling of coordination has been implemented\\nby generating multiple tuples. Passive constructions are elegantly handled by\\nthe grammar itself and lead to identical semantic tuples regardless of active or\\npassive formulation of the same proposition.'),\n",
       " Document(metadata={}, page_content='the grammar itself and lead to identical semantic tuples regardless of active or\\npassive formulation of the same proposition.\\nDue to semantic ambiguity, the deep parser may return more than one reading\\nper sentence. Currently up to three readings are considered (the most probable\\nones according to the treebank-trained parse ranking model), and semantic tu-\\nples are generated for each reading respectively. Multiple readings may collapse\\ninto the same semantic tuple structure, in which case only a single one is stored\\nin the database. Otherwise, a voting mechanism based on rank and number of\\nisomorphic semantic tuples decides for the best selection.'),\n",
       " Document(metadata={}, page_content='in the database. Otherwise, a voting mechanism based on rank and number of\\nisomorphic semantic tuples decides for the best selection.\\nThe following sentence includes the semantic tuple structure (in brackets):\\n“[We]SUBJ [evaluate]PRED [the eﬃciency and performance]DOBJ\\n[against the corpus]ADJU.”\\nIn this example, the conjunction relation connects two noun phrases, both of\\nthem being DOBJ; therefore, no new semantic tuple is necessary. However, we\\ndecided to distinguish cases where conjunction connects two sentences or verb\\nphrases. In such cases, semantic tuples are generated for each part respectively.\\nThe following example shows an AND relation. Conjunction relations may also'),\n",
       " Document(metadata={}, page_content='The following example shows an AND relation. Conjunction relations may also\\nbe realized in diﬀerent lexemes, e.g. and, but, or, as well as, etc.\\nFor the sentence “The system automatically extracts pairs of syntactic units\\nfrom a text and assigns a semantic relation to each pair.”, two semantic tuples\\nare generated separately with their own PRED, DOBJ and OCMP:\\n“[The system]SUBJ [extracts]PRED [pairs of syntactic units]DOBJ\\n[from a text]OCMP [automatically]ADJU.”\\nand\\n“[The system]SUBJ [assigns]PRED [a semantic relation]DOBJ\\n[to each pair]OCMP [automatically]ADJU.”\\nIn passive sentences, the syntactic subject becomes the semantic object and\\nvice versa:'),\n",
       " Document(metadata={}, page_content='[to each pair]OCMP [automatically]ADJU.”\\nIn passive sentences, the syntactic subject becomes the semantic object and\\nvice versa:\\n“[Unseen input]DOBJ [was classiﬁed]PRED [by trained neural networks\\nwith varying error rates depending corpus type]SUBJ.”\\n14\\nUlrich Sch¨afer and Bernd Kiefer\\n3.2\\nFilling the Search Index\\nFor each sentence, the semantic tuple structure together with associated char-\\nacter span information relative to the sentence start is then stored in an Apache\\nSolr5 search index. It also contains metainformation on page number, sentence\\nnumber, oﬀset and document ID.\\nIn case a named entity is identiﬁed by the named entity recognizer, further in-'),\n",
       " Document(metadata={}, page_content='number, oﬀset and document ID.\\nIn case a named entity is identiﬁed by the named entity recognizer, further in-\\nformation on span and type (such as location, person, time) of the item is stored.\\nThis named entity type information is used to identify the answer candidate type\\nin an additional question answering interface we will not further describe in this\\npaper. The following snippet from Solr input for a single sentence may give an\\nimpression of the underlying index schema.\\n<doc>\\n<field name=\"aclaid\">N07-1043</field>\\n<field name=\"page\">2</field>\\n<field name=\"sentno\">56</field>\\n<field name=\"prefix\">N07-1043-s56-p2</field>\\n<field name=\"offset\">353</field>\\n<field name=\"qgen\">PET</field>'),\n",
       " Document(metadata={}, page_content='<field name=\"sentno\">56</field>\\n<field name=\"prefix\">N07-1043-s56-p2</field>\\n<field name=\"offset\">353</field>\\n<field name=\"qgen\">PET</field>\\n<field name=\"sentence\">Sahami et al., (2006) measure semantic\\nsimilarity between two queries using the snippets returned\\nfor those queries by a search engine.</field>\\n<field name=\"subj\">Sahami 2006 et al.</field>\\n<field name=\"subj_start\">0</field>\\n<field name=\"subj_end\">12</field>\\n<field name=\"pred\">measure</field>\\n<field name=\"pred_start\">22</field>\\n<field name=\"pred_end\">28</field>\\n<field name=\"dobj\">semantic similarity</field>\\n<field name=\"dobj_start\">30</field>\\n<field name=\"dobj_end\">48</field>'),\n",
       " Document(metadata={}, page_content='<field name=\"dobj\">semantic similarity</field>\\n<field name=\"dobj_start\">30</field>\\n<field name=\"dobj_end\">48</field>\\n<field name=\"ocmp\">between two queries using the snippets\\nreturned for those queries by a search engine</field>\\n<field name=\"ocmp_start\">0</field>\\n<field name=\"ocmp_end\">133</field>\\n<field name=\"ner_types\">citation ne-term ne-term </field>\\n<field name=\"ner_cstart\">0 30 121 </field>\\n<field name=\"ner_cend\">20 48 133 </field>\\n<field name=\"ner_surface\">\"Sahami et al., (2006)\"\\n\"semantic similarity\"\\n\"search engine\" </field>\\n</doc>\\nTo sum up the overall oﬄine analysis for search index generation, Figure 8\\ndepicts the oﬄine NLP and semantic tuple extraction workﬂow.'),\n",
       " Document(metadata={}, page_content='</doc>\\nTo sum up the overall oﬄine analysis for search index generation, Figure 8\\ndepicts the oﬄine NLP and semantic tuple extraction workﬂow.\\n5 http://lucene.apache.org/solr\\nAdvances in Deep Parsing of Scholarly Paper Content\\n15\\n Heart \\n of Gold\\n Heart \\n of Gold\\n Heart \\n of Gold\\n Heart \\n of Gold\\nsemantic tuples\\ndatabase\\nsemantic tuples\\ndatabase\\n● text cleaning\\n● XML encoding\\n● text cleaning\\n● XML encoding\\n Heart \\n of Gold\\n Heart \\n of Gold\\n Heart \\n of Gold\\n Heart \\n of Gold\\nNLP grid with \\nJTok, TnT, \\nSProUT, PET\\nsemantic tuples\\nextraction\\nsemantic tuples\\nextraction\\n+\\n+\\nscholarly papers\\n2 GB PDF\\nOCR-based\\nPDF-to-text\\nextraction \\nOCR-based\\nPDF-to-text\\nextraction \\nHeart \\nof Gold\\nHeart \\nof Gold'),\n",
       " Document(metadata={}, page_content='extraction\\n+\\n+\\nscholarly papers\\n2 GB PDF\\nOCR-based\\nPDF-to-text\\nextraction \\nOCR-based\\nPDF-to-text\\nextraction \\nHeart \\nof Gold\\nHeart \\nof Gold\\nAutomatic\\nNLP XML\\nannotation\\n1 GB Apache Solr Blob (approx. 1.5 million sentences)\\nFig. 8. Grid-based hybrid parsing of the scientiﬁc paper corpus\\n3.3\\nQuery Interface\\nAs depicted in Figure 9, the user interface for semantic paper search contains\\nthree text ﬁelds where the user can input subject, predicate and all remaining\\nstructures (rest). The latter is combined to ease input (otherwise users would\\nbecome worried about what to put in OCMP or ADJU) and will be expanded\\nto a disjunctive Solr/Lucene query expression.\\nFig. 9. Simple query interface'),\n",
       " Document(metadata={}, page_content='become worried about what to put in OCMP or ADJU) and will be expanded\\nto a disjunctive Solr/Lucene query expression.\\nFig. 9. Simple query interface\\nTo give an example, a semantic tuple search expression with input to ﬁeld\\nsubject=*, input to ﬁeld predicate=‘measure’, and input to ﬁeld rest=‘semantic\\nsimilarity’ is translated into an Apache Solr query\\npred:measure +(dobj:\"semantic similarity\"\\n16\\nUlrich Sch¨afer and Bernd Kiefer\\nOR ocmp:\"semantic similarity\"\\nOR adju:\"semantic similarity\")\\nIn case WordNet synset [10] expansion is enabled, measure is replaced by\\n(measure OR evaluate OR quantify OR value OR assess OR valuate).'),\n",
       " Document(metadata={}, page_content='In case WordNet synset [10] expansion is enabled, measure is replaced by\\n(measure OR evaluate OR quantify OR value OR assess OR valuate).\\nIt is planned to also allow for synonym search in the SUBJ and REST ﬁeld.\\nHere, domain ontology information as well as automatically identiﬁed similar\\n(multi-word) terms could be used to expand the query.\\nSearch Results for * “measure” “semantic similarity”\\n– N07-1043: Sahami et al., (2006) [measure]PRED [semantic similarity]DOBJ\\nbetween two queries using the snippets returned for those queries by a\\nsearch engine.\\n– W04-0106: [Semantic similarity]DOBJ [is measured]PRED in terms of sim-\\nilar word contexts.'),\n",
       " Document(metadata={}, page_content='search engine.\\n– W04-0106: [Semantic similarity]DOBJ [is measured]PRED in terms of sim-\\nilar word contexts.\\n– N07-1044: [The semantic similarity]DOBJ between neighbors and senses [is\\nmeasured]PRED using a manually crafted taxonomy such as WordNet (see\\nBudanitsky and Hirst 2001 for an overview of WordNet-based similarity\\nmeasures).\\n– P08-1028: We [assessed]PRED [a wide range of semantic similarity\\nmeasures]DOBJ using the WordNet similarity package (Pedersen et al.,\\n2004).\\n– W06-3802:\\nUsing\\nWordNet,\\nwe\\n[can\\nmeasure]PRED\\n[the\\nsemantic\\nsimilarity]DOBJ or relatedness between a pair of concepts (or word senses),\\nand by extension, between a pair of sentences.\\n– W06-1659:\\nUsing\\nWordNet,\\nwe\\n[can'),\n",
       " Document(metadata={}, page_content='and by extension, between a pair of sentences.\\n– W06-1659:\\nUsing\\nWordNet,\\nwe\\n[can\\nmeasure]PRED\\n[the\\nsemantic\\nsimilarity]DOBJ or relatedness between a pair of concepts (or word senses),\\nand by extension, between a pair of sentences.\\n– W05-1203: For entailment identiﬁcation, since this is a directional relation,\\nwe [only measure]PRED [the semantic similarity]DOBJ with respect to the\\nhypothesis (the text that is entailed).\\n– W06-1104: We [measured]PRED [semantic relat-edness instead of semantic\\nsimilarity]DOBJ.\\n– P06-1112:\\n3.\\n[The\\nsemantic\\nsimilarity\\nSemSim(h\\n,\\nh\\n)]DOBJ\\n[is\\nmeasured]PRED using Word-Net and eXtended WordNet.\\n. . .'),\n",
       " Document(metadata={}, page_content='similarity]DOBJ.\\n– P06-1112:\\n3.\\n[The\\nsemantic\\nsimilarity\\nSemSim(h\\n,\\nh\\n)]DOBJ\\n[is\\nmeasured]PRED using Word-Net and eXtended WordNet.\\n. . .\\nFig. 10. The ﬁrst matching sentences in the ACL Anthology subset 2002-2008 with\\nrecognized variation in predicate synsets (assess, measure, evaluate) and passive con-\\nstructions\\nThe result is then a list of sentence snippets (Figure 10). By clicking on a\\nhyperlink underlying the snippet text, the original PDF is opened. By using\\nthe information on page and sentence text/oﬀset in the Apache Solr answer,\\nthe result sentence is highlighted as shown in Figure 11. This helps to quickly'),\n",
       " Document(metadata={}, page_content='the result sentence is highlighted as shown in Figure 11. This helps to quickly\\nidentify relevance of the answer by looking at context in the original layout.\\nAdvances in Deep Parsing of Scholarly Paper Content\\n17\\nFig. 11. First result sentence (from N07-1043) highlighted in original PDF\\n4\\nRelated Work\\nUsing HPSG combined with shallow domain-speciﬁc modeling for high-precision\\nanalysis of scientiﬁc texts is an emerging research area. Another ERG-based\\napproach to relation and information extraction from scientiﬁc texts is SciBorg\\n[13]. SciBorg mainly deals with chemistry research papers and handles domain-\\nspeciﬁc phenomena with a specialized named entity recognizer. It relies on a'),\n",
       " Document(metadata={}, page_content='speciﬁc phenomena with a specialized named entity recognizer. It relies on a\\nshallow parser as robustness fall-back for MRS generation.\\nOther groups use less elaborated and ﬁne-grained HPSG grammars than\\nERG. [11] report on large-scale parsing of MEDLINE articles (1.4 billion words)\\nwith such a simpliﬁed grammar.\\n[14] use shallow dependency structure and results from HPSG parsing for\\nextracting protein-protein interactions (PPI) from research papers. The same\\ngroup has also worked on medical texts: MEDIE6 is a semantic search engine to\\nretrieve biomedical correlations from MEDLINE articles.\\nWhat distinguishes our approach from those, besides concentration on a dif-'),\n",
       " Document(metadata={}, page_content='retrieve biomedical correlations from MEDLINE articles.\\nWhat distinguishes our approach from those, besides concentration on a dif-\\nferent scientiﬁc area, is the focus on and use of ontology information as integrated\\npart of linguistic analysis, use of the most comprehensive and elaborated HPSG\\ngrammar for English (ERG), and the interactive user interface (Scientist’s Work-\\nbench application; [17]) and editor [18].\\n5\\nConclusion and Future Work\\nWe have presented our recent advances in full, robust parsing of scientiﬁc papers\\ntexts. By careful preprocessing and novel approaches to eﬃcient parsing of long\\nsentences, we could improve coverage from 65 to more than 85%.'),\n",
       " Document(metadata={}, page_content='texts. By careful preprocessing and novel approaches to eﬃcient parsing of long\\nsentences, we could improve coverage from 65 to more than 85%.\\nThe semantic search application built on the semantic representations gen-\\nerated by the deep grammar is a useful extension to cope with synonyms and\\nsyntactic variation when querying full scientiﬁc publication content. The search\\nspace, initially expanded by adding synonymns, can be again constrained by\\nimposing semantic subject-predicate-object structure in the query.\\n6 http://www-tsujii.is.s.u-tokyo.ac.jp/medie/\\n18\\nUlrich Sch¨afer and Bernd Kiefer\\nFurther research goals are improving robustness of the NLP tool chain. We'),\n",
       " Document(metadata={}, page_content='18\\nUlrich Sch¨afer and Bernd Kiefer\\nFurther research goals are improving robustness of the NLP tool chain. We\\nare also working on generic techniques to automatically extract and use sci-\\nence domain information from the underlying paper corpus to improve targeted\\nsearch. Three main tasks in our focus are coreference resolution, term extraction\\nand ontology extraction viz. population. The idea is that these techniques, in a\\nﬁrst step gained independently from the text corpus or partially from NLP anal-\\nyses of it, will beneﬁt from each other and can be used to build more reliable\\nand precise resources and tools in a bootstrapping process.'),\n",
       " Document(metadata={}, page_content='yses of it, will beneﬁt from each other and can be used to build more reliable\\nand precise resources and tools in a bootstrapping process.\\nHandling of negation, modal constructions, subclauses etc. also fall into the\\ncategory deep NLP can handle, but this will be addressed in the future as it also\\nrequires lexico-semantic information of verbs etc. in the extraction process. It\\nwill deﬁnitely be an important extension helping to improve precision in search.\\nThe semantic search application is part of the Scientist’s workbench and is\\ncomplemented by a visualization and navigation tool TeeCeeGeeNav [16] that\\nsupports scientists in quickly getting an overview of a (new) research ﬁeld by'),\n",
       " Document(metadata={}, page_content='supports scientists in quickly getting an overview of a (new) research ﬁeld by\\nbrowsing through a typed citation graph computed from the scientiﬁc paper\\ncorpus. The citation classiﬁcation with categories such as use or refutation of\\nresults of the cited paper currently builds on shallow NLP (such as PoS tagging)\\nonly. In the future, deep semantics could help too further improve this diﬃcult\\nclassiﬁcation task.\\nAcknowledgments\\nThe authors would like to thank Peter Adolphs, Dan Flickinger and Stephan\\nOepen for their support and numerous fruitful discussions. We would also like\\nto thank Yi Zhang and Bart Cramer for the implementation of chart pruning in'),\n",
       " Document(metadata={}, page_content='to thank Yi Zhang and Bart Cramer for the implementation of chart pruning in\\nPET and their support to put it into use. The work described in this paper has\\nbeen carried out in the context of the project TAKE (Technologies for Advanced\\nKnowledge Extraction), funded under contract 01IW08003 by the German Fed-\\neral Ministry of Education and Research, and in the context of the world-wide\\nDELPH-IN collaboration7.\\nReferences\\n1. Adolphs, P., Oepen, S., Callmeier, U., Crysmann, B., Flickinger, D., Kiefer, B.:\\nSome ﬁne points of hybrid natural language parsing. In: Proc. of LREC. pp. 1380–\\n1387. Marrakesh, Morocco (2008)'),\n",
       " Document(metadata={}, page_content='Some ﬁne points of hybrid natural language parsing. In: Proc. of LREC. pp. 1380–\\n1387. Marrakesh, Morocco (2008)\\n2. Bird, S., Dale, R., Dorr, B., Gibson, B., Joseph, M., Kan, M.Y., Lee, D., Powley,\\nB., Radev, D., Tan, Y.F.: The ACL anthology reference corpus: A reference dataset\\nfor bibliographic research. In: Proc. of LREC. pp. 1755–1759. Marrakesh, Morocco\\n(2008)\\n3. Brants, T.: TnT – A Statistical Part-of-Speech Tagger. In: Proc. of ANLP-2000.\\npp. 224–231. Seattle, WA (2000)\\n7 DEep Linguistic Processing with Hpsg INitiative; http://www.delph-in.net\\nAdvances in Deep Parsing of Scholarly Paper Content\\n19\\n4. Callmeier, U.: PET – A platform for experimentation with eﬃcient HPSG process-'),\n",
       " Document(metadata={}, page_content='Advances in Deep Parsing of Scholarly Paper Content\\n19\\n4. Callmeier, U.: PET – A platform for experimentation with eﬃcient HPSG process-\\ning techniques. Natural Language Engineering 6(1), 99–108 (2000)\\n5. Copestake, A., Flickinger, D.: An open-source grammar development environment\\nand broad-coverage English grammar using HPSG. In: Proc. of LREC. pp. 591–\\n598. Athens, Greece (2000)\\n6. Copestake, A., Flickinger, D., Sag, I.A., Pollard, C.: Minimal recursion semantics:\\nan introduction. Research on Language and Computation 3(2–3), 281–332 (2005)\\n7. Cramer, B., Zhang, Y.: Constraining robust constructions for broad-coverage pars-'),\n",
       " Document(metadata={}, page_content='7. Cramer, B., Zhang, Y.: Constraining robust constructions for broad-coverage pars-\\ning with precision grammars. In: Proc. of COLING. pp. 223–231. Beijing, China\\n(2010)\\n8. Dro˙zd˙zy´nski, W., Krieger, H.U., Piskorski, J., Sch¨afer, U., Xu, F.: Shallow process-\\ning with uniﬁcation and typed feature structures – foundations and applications.\\nK¨unstliche Intelligenz 2004(1), 17–23 (2004)\\n9. Flickinger, D., Oepen, S., Ytrestøl, G.: WikiWoods: Syntacto-semantic annotation\\nfor English Wikipedia. In: Proc. of LREC. pp. 1665–1671. Valletta, Malta (2010)\\n10. Miller, G.A., Beckwith, R., Fellbaum, C., Gross, D., Miller, K.J.: Five papers on'),\n",
       " Document(metadata={}, page_content='10. Miller, G.A., Beckwith, R., Fellbaum, C., Gross, D., Miller, K.J.: Five papers on\\nWordNet. Tech. rep., Cognitive Science Laboratory, Princeton University (1993)\\n11. Ninomiya, T., Tsuruoka, Y., Miyao, Y., Taura, K., Tsujii, J.: Fast and scalable\\nHPSG parsing. Traitement automatique des langues (TAL) 46(2) (2006)\\n12. Pollard, C., Sag, I.A.: Head-Driven Phrase Structure Grammar. Studies in Con-\\ntemporary Linguistics, University of Chicago Press, Chicago (1994)\\n13. Rupp, C., Copestake, A., Corbett, P., Waldron, B.: Integrating general-purpose\\nand domain-speciﬁc components in the analysis of scientiﬁc text. In: Proc. of the\\nUK e-Science Programme All Hands Meeting 2007. Nottingham, UK (2007)'),\n",
       " Document(metadata={}, page_content='UK e-Science Programme All Hands Meeting 2007. Nottingham, UK (2007)\\n14. Sætre, R., Kenji, S., Tsujii, J.: Syntactic features for protein-protein interaction\\nextraction. In: Baker, C.J., Jian, S. (eds.) Short Paper Proc. of the 2nd Int. Symp.\\non Languages in Biology and Medicine (LBM 2007). pp. 6.1–6.14. Singapore (2008)\\n15. Sch¨afer, U.: Middleware for creating and combining multi-dimensional NLP\\nmarkup. In: Proc. of the EACL-2006 Workshop on Multi-dimensional Markup in\\nNatural Language Processing. pp. 81–84. Trento, Italy (2006)\\n16. Sch¨afer, U., Kasterka, U.: Scientiﬁc authoring support: A tool to navigate in typed'),\n",
       " Document(metadata={}, page_content='Natural Language Processing. pp. 81–84. Trento, Italy (2006)\\n16. Sch¨afer, U., Kasterka, U.: Scientiﬁc authoring support: A tool to navigate in typed\\ncitation graphs. In: Proc. of the NAACL-HLT 2010 Workshop on Computational\\nLinguistics and Writing. pp. 7–14. Los Angeles, CA (2010)\\n17. Sch¨afer, U., Spurk, C.: TAKE Scientist’s Workbench: Semantic search and citation-\\nbased visual navigation in scholar papers. In: Proc. of the 4th IEEE Int. Conference\\non Semantic Computing (ICSC-2010). pp. 317–324. Pittsburgh, PA (2010)\\n18. Sch¨afer, U., Uszkoreit, H., Federmann, C., Marek, T., Zhang, Y.: Extracting and\\nquerying relations in scientiﬁc papers. In: Proc. of the 31st Annual German Confer-'),\n",
       " Document(metadata={}, page_content='querying relations in scientiﬁc papers. In: Proc. of the 31st Annual German Confer-\\nence on Artiﬁcial Intelligence (KI-2008). pp. 127–134. Springer LNAI 5243 (2008)')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d066a563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
