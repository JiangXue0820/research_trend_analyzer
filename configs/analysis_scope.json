{
  "DP_theory": {
    "definition": "研究差分隐私的数学理论：含形式化定义与等价/推广（如 Rényi/zCDP）、组合/放大与隐私记账、机制与最优噪声设计、隐私–效用/样本复杂度界限等，提供严格证明或新理论结果；排除仅工程实现或无新理论贡献的经验论文。",
    "keywords": [
      "differential privacy",
      "rényi differential privacy",
      "concentrated differential privacy",
      "zero-concentrated differential privacy",
      "moment accountant",
      "rdp accountant",
      "privacy accounting",
      "composition theorem",
      "privacy amplification",
      "subsampling amplification",
      "privacy budget",
      "epsilon-delta differential privacy",
      "gaussian mechanism",
      "laplace mechanism",
      "privacy-utility trade-off",
      "privacy loss distribution",
      "private aggregation of teacher ensembles (PATE)"
    ]
  },
  "AI_attacks": {
    "definition": "针对 LLM/Agent/RAG 的隐私与安全攻击，覆盖如数据抽取、成员/属性推断、模型反演、数据投毒/后门、提示注入与越狱、模型抽取、工具/函数滥用、运行期外泄等；强调提出或迁移攻击方法并给出实证/理论证据。排除纯防御、政策评论、与 LLM/Agent/RAG 无关的传统攻击。",
    "keywords": [
      "training data extraction",
      "training data memorization",
      "system prompt leakage",
      "pii leakage",
      "regurgitation",
      "membership inference",
      "attribute inference",
      "model inversion",
      "data poisoning",
      "backdoor attack",
      "prompt injection",
      "indirect prompt injection",
      "jailbreak",
      "red teaming attack",
      "automated red teaming",
      "adversarial suffix",
      "retrieval poisoning",
      "rag poisoning",
      "tool injection",
      "function calling attack",
      "data exfiltration",
      "model extraction",
      "model stealing",
      "knockoff model",
      "watermark removal",
      "evasion attack",
      "unicode-based obfuscation",
      "homoglyph attack",
      "zero-width character attack"
    ]
  },
  "AI_defenses": {
    "definition": "面向 LLM/Agent/RAG 的防护技术与工程化护栏，包括训练期隐私保护（数据清洗、差分隐私微调、安全对齐、模型遗忘）与推理期防护（提示/注入防御、输出管控、RAG 加固、权限与受约束解码等）。",
    "keywords": [
      "pii detection",
      "de-identification",
      "jailbreak defense",
      "prompt injection defense",
      "safety fine-tuning",
      "constitutional ai",
      "output moderation",
      "output guardrails",
      "safety classifier",
      "safety alignment",
      "differentially private fine-tuning",
      "privacy-preserving fine-tuning",
      "private inference",
      "federated learning for LLMs",
      "machine unlearning",
      "memorization reduction",
      "exposure mitigation",
      "rag hardening",
      "source attribution",
      "citation grounding",
      "tool permissioning",
      "least privilege",
      "function calling guard",
      "network egress control",
      "constrained decoding",
      "grammar-based decoding",
      "content provenance",
      "multi-stage safety pipeline"
    ]
  },
  "AI_audit": {
    "definition": "研究 AI 模型与系统进行的持续化隐私/安全评测与合规审计，强调基准与评测方法（基准套件/数据集/指标/协议、自动化评测与一致性校准），而非提出新攻击或新防御。",
    "keywords": [
      "safety benchmark",
      "robustness benchmark",
      "privacy benchmark",
      "prompt injection benchmark",
      "jailbreak benchmark",
      "benchmark suite",
      "benchmark dataset",
      "evaluation framework",
      "evaluation protocol",
      "automated evaluation",
      "LLM-as-a-Judge",
      "pairwise comparison",
      "Elo rating",
      "arena evaluation",
      "leaderboard",
      "meta-evaluation",
      "judge reliability",
      "calibration with human ratings",
      "inter-annotator agreement",
      "coverage metric",
      "attack success rate",
      "risk score",
      "exposure estimation",
      "memorization audit",
      "system prompt leakage evaluation",
      "continuous evaluation"
    ]
  },
  "usable_privacy": {
    "definition": "用于筛选：从用户视角研究隐私/安全之可用性与可接受性，既覆盖用户偏好与期望（user preferences、privacy/safety expectations、contextual integrity：角色/关系/目的/地点/数据类型等）及其在不同情境下的披露/共享决策，也覆盖与之相关的界面与流程（隐私告知与同意、权限与设置、隐私标签、风险沟通、反暗黑模式、数据主体权利操作）。通常提供偏好/期望或行为层面的实证证据（调查/访谈/日志/选择实验/可用性评估等）。",
    "keywords": [
      "user preferences",
      "privacy personas",
      "privacy expectations",
      "safety expectations",
      "contextual integrity",
      "information flows",
      "acceptable use norms",
      "risk perception",
      "privacy calculus",
      "data sensitivity",
      "willingness to share",
      "disclosure decisions",
      "preference elicitation",
      "conjoint analysis",
      "choice experiment",
      "privacy attitudes",
      "privacy concern",
      "perceived acceptability",
      "expectation–behavior gap",
      "contextual norms",
      "audience control",
      "bystander privacy",
      "location privacy",
      "privacy notice",
      "informed consent",
      "consent dialog",
      "just-in-time notice",
      "permission dialog",
      "privacy settings",
      "privacy dashboard",
      "privacy label",
      "data nutrition label",
      "app tracking transparency",
      "risk communication",
      "dark patterns",
      "deceptive design",
      "nudging",
      "habituation",
      "privacy defaults",
      "data subject access request (dsar)",
      "data deletion request",
      "data practice transparency"
    ]
  }
}
