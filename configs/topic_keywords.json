{
  "privacy": [
    "anonymity",
    "anonymization",
    "anonymous",
    "confidentiality",
    "consent",
    "data extraction",
    "data governance",
    "data minimization",
    "data protection",
    "de-identification",
    "differential privacy",
    "ethics",
    "federated learning",
    "gdpr",
    "homomorphic encryption",
    "information privacy",
    "k-anonymity",
    "leakage",
    "membership inference",
    "model inversion",
    "privacy",
    "privacy by design",
    "privacy-by-design",
    "privacy-preserving machine learning",
    "private",
    "pseudonymization",
    "re-identification",
    "secure multi-party computation",
    "security",
    "surveillance"
  ],
  "llm_safety": [
    "alignment",
    "bias",
    "ethics",
    "fairness",
    "generative ai",
    "guardrails",
    "hallucination",
    "jailbreak",
    "large language model",
    "llm safety",
    "misinformation",
    "privacy",
    "prompt injection",
    "red teaming",
    "responsible ai",
    "risk assessment",
    "robustness",
    "safety alignment",
    "toxicity",
    "trustworthiness"
  ]
}